{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Noise\"></a>\n",
    "\n",
    "# Re3d Dataset Adding Noise\n",
    "\n",
    "The Re3d Dataset is a dataset compiled for Named Entity Recognition (NER) on the subject of National Defense. The data includes sources such as:\n",
    "\n",
    "* Australian Department of Foreign Affiars\n",
    "* BBC Online\n",
    "* CENTCOM\n",
    "* Delegation of the European Union to Syria\n",
    "* UK Government\n",
    "* US State Department\n",
    "* Wikipedia\n",
    "\n",
    "This notebook explores how to add noise to the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path('notebooks/noise.ipynb').resolve().parents[2]\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "PREPARED_DIR = DATA_DIR / \"prepared\"\n",
    "NOISE_DIR = PREPARED_DIR / \"noise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>word</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>tags</th>\n",
       "      <th>single_tag</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[B-Temporal]</td>\n",
       "      <td>B-Temporal</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>week</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>[I-Temporal]</td>\n",
       "      <td>I-Temporal</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sees</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>start</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_num   word  start_idx  end_idx          tags  single_tag   POS\n",
       "0             0   This          0        4  [B-Temporal]  B-Temporal  PRON\n",
       "1             0   week          5        9  [I-Temporal]  I-Temporal  NOUN\n",
       "2             0   sees         10       14           [O]           O  VERB\n",
       "3             0    the         15       18           [O]           O  PRON\n",
       "4             0  start         19       24           [O]           O  VERB"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "df = pd.read_csv(PREPARED_DIR / \"master.csv\")\n",
    "df[\"tags\"] = df[\"tags\"].apply(literal_eval)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlner.utils import SentenceGetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 928 total sentences\n"
     ]
    }
   ],
   "source": [
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences\n",
    "print(f\"There are {len(sentences)} total sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to split the dataset into train, validation, and test subsets. We will apply varying amounts of noise to the train subset while leaving the validation and test sets be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.Random(42).shuffle(sentences)\n",
    "\n",
    "total_sentences = len(sentences)\n",
    "val_idx = int(total_sentences * 0.8)\n",
    "test_idx = val_idx + int(total_sentences * 0.1)\n",
    "\n",
    "train_sentences = sentences[:val_idx]\n",
    "val_sentences = sentences[val_idx: test_idx]\n",
    "test_sentences = sentences[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Sentences: 742\n",
      "Number of Validation Sentences: 92\n",
      "Number of Test Sentences: 94\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Train Sentences: {len(train_sentences)}\")\n",
    "print(f\"Number of Validation Sentences: {len(val_sentences)}\")\n",
    "print(f\"Number of Test Sentences: {len(test_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlner.noise import add_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    # Load master data\n",
    "    df = pd.read_csv(PREPARED_DIR / \"master.csv\")\n",
    "    df[\"tags\"] = df[\"tags\"].apply(literal_eval)\n",
    "\n",
    "    # Gather as sequences\n",
    "    getter = SentenceGetter(df)\n",
    "    sentences = getter.sentences\n",
    "\n",
    "    # Split into train, val, test\n",
    "    random.Random(42).shuffle(sentences)\n",
    "    total_sentences = len(sentences)\n",
    "    val_idx = int(total_sentences * 0.8)\n",
    "    test_idx = val_idx + int(total_sentences * 0.1)\n",
    "\n",
    "    train_sentences = sentences[:val_idx]\n",
    "    val_sentences = sentences[val_idx: test_idx]\n",
    "    test_sentences = sentences[test_idx:]\n",
    "\n",
    "    # Save val/test\n",
    "    NOISE_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    with open(PREPARED_DIR / \"validation.joblib\", \"wb\") as fp:\n",
    "        joblib.dump(val_sentences, fp, compress=3)\n",
    "\n",
    "    with open(PREPARED_DIR / \"test.joblib\", \"wb\") as fp:\n",
    "        joblib.dump(test_sentences, fp, compress=3)\n",
    "\n",
    "    # Apply noise and save\n",
    "    noisy_percentages = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "    for percentage in tqdm(noisy_percentages, desc=\"Noise Percentages\"):\n",
    "        noisy_sentences = add_noise(train_sentences, percentage)\n",
    "\n",
    "        with open(NOISE_DIR / f\"noise_{percentage}.joblib\", \"wb\") as fp:\n",
    "            joblib.dump(noisy_sentences, fp, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1566ea1af4a47ca7acc671ba85a809484c1db5e7319af0d3caf0750117059574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
