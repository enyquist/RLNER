{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Prepare Data\"></a>\n",
    "\n",
    "# Prepare Re3d Dataset for NER\n",
    "\n",
    "The Re3d Dataset is a dataset compiled for Named Entity Recognition (NER) on the subject of National Defense. The data includes sources such as:\n",
    "\n",
    "* Australian Department of Foreign Affiars\n",
    "* BBC Online\n",
    "* CENTCOM\n",
    "* Delegation of the European Union to Syria\n",
    "* UK Government\n",
    "* US State Department\n",
    "* Wikipedia\n",
    "\n",
    "To prepare this datset, we will need tokenized words, their BIO tags, and the sentence number they belong to. Let's investigate how the data is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path('notebooks/format_data.ipynb').resolve().parents[2]\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PREPARED_DIR = DATA_DIR / \"prepared\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RAW_DIR / \"UK Government/documents.json\", \"r\") as fp:\n",
    "    lines = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"_id\" : \"09FF200CBB76594D688F8EB565717543\", \"sourceName\" : \"UK Government\", \"sourceUrl\" : \"https://www.gov.uk/government/news/minister-for-the-middle-east-condemns-attack-in-baghdad\", \"wordCount\" : 95, \"sentenceCount\" : 5, \"title\" : \"Minister for the Middle East condemns attack in Baghdad\", \"text\" : \"Minister for the Middle East, Tobias Ellwood, responds to the attack in the Karrada district of Baghdad\\\\n\\\\nForeign Office Minister, Tobias Ellwood, said:\\\\n\\\\nThe attack was a horrific act of terror against innocent people in the early hours of Sunday morning in Karrada, Baghdad. I offer my sincere condolences to the families and friends of the victims, and hope those injured in the attack recover quickly.\\\\n\\\\nDaesh targeted families out shopping for Eid and those celebrating suhur. It violated the peace of Ramadan. The UK stands by Iraq to defeat Daesh and end this violence.\" }\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first document from UK Government. What data type is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to ingest these documents as literal dictionaries, not as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '09FF200CBB76594D688F8EB565717543',\n",
       " 'sourceName': 'UK Government',\n",
       " 'sourceUrl': 'https://www.gov.uk/government/news/minister-for-the-middle-east-condemns-attack-in-baghdad',\n",
       " 'wordCount': 95,\n",
       " 'sentenceCount': 5,\n",
       " 'title': 'Minister for the Middle East condemns attack in Baghdad',\n",
       " 'text': 'Minister for the Middle East, Tobias Ellwood, responds to the attack in the Karrada district of Baghdad\\n\\nForeign Office Minister, Tobias Ellwood, said:\\n\\nThe attack was a horrific act of terror against innocent people in the early hours of Sunday morning in Karrada, Baghdad. I offer my sincere condolences to the families and friends of the victims, and hope those injured in the attack recover quickly.\\n\\nDaesh targeted families out shopping for Eid and those celebrating suhur. It violated the peace of Ramadan. The UK stands by Iraq to defeat Daesh and end this violence.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = literal_eval(lines[0])\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dictionary, we need to tokenize the text. We will use spaCy as it has higher performance splitting named entities correctly (i.e. U.S. as one token) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minister\n",
      "for\n",
      "the\n",
      "Middle\n",
      "East\n",
      ",\n",
      "Tobias\n",
      "Ellwood\n",
      ",\n",
      "responds\n",
      "to\n",
      "the\n",
      "attack\n",
      "in\n",
      "the\n",
      "Karrada\n",
      "district\n",
      "of\n",
      "Baghdad\n",
      "\n",
      "\n",
      "\n",
      "Foreign\n",
      "Office\n",
      "Minister\n",
      ",\n",
      "Tobias\n",
      "Ellwood\n",
      ",\n",
      "said\n",
      ":\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "attack\n",
      "was\n",
      "a\n",
      "horrific\n",
      "act\n",
      "of\n",
      "terror\n",
      "against\n",
      "innocent\n",
      "people\n",
      "in\n",
      "the\n",
      "early\n",
      "hours\n",
      "of\n",
      "Sunday\n",
      "morning\n",
      "in\n",
      "Karrada\n",
      ",\n",
      "Baghdad\n",
      ".\n",
      "I\n",
      "offer\n",
      "my\n",
      "sincere\n",
      "condolences\n",
      "to\n",
      "the\n",
      "families\n",
      "and\n",
      "friends\n",
      "of\n",
      "the\n",
      "victims\n",
      ",\n",
      "and\n",
      "hope\n",
      "those\n",
      "injured\n",
      "in\n",
      "the\n",
      "attack\n",
      "recover\n",
      "quickly\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "Daesh\n",
      "targeted\n",
      "families\n",
      "out\n",
      "shopping\n",
      "for\n",
      "Eid\n",
      "and\n",
      "those\n",
      "celebrating\n",
      "suhur\n",
      ".\n",
      "It\n",
      "violated\n",
      "the\n",
      "peace\n",
      "of\n",
      "Ramadan\n",
      ".\n",
      "The\n",
      "UK\n",
      "stands\n",
      "by\n",
      "Iraq\n",
      "to\n",
      "defeat\n",
      "Daesh\n",
      "and\n",
      "end\n",
      "this\n",
      "violence\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "doc = nlp(document[\"text\"])\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of these tokens are labeled as entities, and what type of entity are they? We have copied the entities raw from the entities.json file for ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-0-0-28-Person\", \"begin\" : 0, \"end\" : 28, \"type\" : \"Person\", \"value\" : \"Minister for the Middle East\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-0-105-128-Person\", \"begin\" : 105, \"end\" : 128, \"type\" : \"Person\", \"value\" : \"Foreign Office Minister\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-0-130-144-Person\", \"begin\" : 130, \"end\" : 144, \"type\" : \"Person\", \"value\" : \"Tobias Ellwood\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-0-17-28-Location\", \"begin\" : 17, \"end\" : 28, \"type\" : \"Location\", \"value\" : \"Middle East\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 0 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-0-224-245-Temporal\", \"begin\" : 224, \"end\" : 245, \"type\" : \"Temporal\", \"value\" : \"early hours of Sunday\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-0-257-264-Location\", \"begin\" : 257, \"end\" : 264, \"type\" : \"Location\", \"value\" : \"Karrada\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-0-266-273-Location\", \"begin\" : 266, \"end\" : 273, \"type\" : \"Location\", \"value\" : \"Baghdad\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-0-30-44-Person\", \"begin\" : 30, \"end\" : 44, \"type\" : \"Person\", \"value\" : \"Tobias Ellwood\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-0-72-103-Location\", \"begin\" : 72, \"end\" : 103, \"type\" : \"Location\", \"value\" : \"the Karrada district of Baghdad\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-0-96-103-Location\", \"begin\" : 96, \"end\" : 103, \"type\" : \"Location\", \"value\" : \"Baghdad\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 0 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-1-0-1-Person\", \"begin\" : 275, \"end\" : 276, \"type\" : \"Person\", \"value\" : \"I\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-1-79-83-Person\", \"begin\" : 354, \"end\" : 358, \"type\" : \"Person\", \"value\" : \"hope\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 0 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-2-0-5-Organisation\", \"begin\" : 405, \"end\" : 410, \"type\" : \"Organisation\", \"value\" : \"Daesh\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-2-15-23-Organisation\", \"begin\" : 420, \"end\" : 428, \"type\" : \"Organisation\", \"value\" : \"families\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-3-25-32-Temporal\", \"begin\" : 504, \"end\" : 511, \"type\" : \"Temporal\", \"value\" : \"Ramadan\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-4-0-6-Organisation\", \"begin\" : 513, \"end\" : 519, \"type\" : \"Organisation\", \"value\" : \"The UK\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-4-17-21-Location\", \"begin\" : 530, \"end\" : 534, \"type\" : \"Location\", \"value\" : \"Iraq\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 0 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-4-17-21-Organisation\", \"begin\" : 530, \"end\" : 534, \"type\" : \"Organisation\", \"value\" : \"Iraq\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 0.97 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-4-32-37-Organisation\", \"begin\" : 545, \"end\" : 550, \"type\" : \"Organisation\", \"value\" : \"Daesh\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 1 },\n",
    "{ \"_id\" : \"09FF200CBB76594D688F8EB565717543-4-4-6-Location\", \"begin\" : 517, \"end\" : 519, \"type\" : \"Location\", \"value\" : \"UK\", \"documentId\" : \"09FF200CBB76594D688F8EB565717543\", \"confidence\" : 0 }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These entities have type (label) and start (begin) and end (end) character spans. We will need to first find the character spans of the tokens generated previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Union\n",
    "\n",
    "Re3dDict = Dict[str, Union[str, int]]\n",
    "TokenSpan = List[Tuple[int, str, int, int]]\n",
    "\n",
    "def get_token_spans(text: str) -> TokenSpan:\n",
    "    \"\"\"Generate Token Spans given text\n",
    "\n",
    "    Args:\n",
    "        text (str): raw text\n",
    "\n",
    "    Returns:\n",
    "        TokenSpan: List of (sentence_idx, word, index_start, index_end)\n",
    "    \"\"\"\n",
    "\n",
    "    doc = nlp(text)\n",
    "    token_spans = []\n",
    "    for sentence_idx, sent in enumerate(doc.sents):\n",
    "        for token in sent:\n",
    "            token_span = doc[token.i : token.i + 1]\n",
    "            token_spans.append((sentence_idx, token.text, token_span.start_char, token_span.end_char))\n",
    "\n",
    "    return token_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Minister', 0, 8),\n",
       " (0, 'for', 9, 12),\n",
       " (0, 'the', 13, 16),\n",
       " (0, 'Middle', 17, 23),\n",
       " (0, 'East', 24, 28),\n",
       " (0, ',', 28, 29),\n",
       " (0, 'Tobias', 30, 36),\n",
       " (0, 'Ellwood', 37, 44),\n",
       " (0, ',', 44, 45),\n",
       " (0, 'responds', 46, 54),\n",
       " (0, 'to', 55, 57),\n",
       " (0, 'the', 58, 61),\n",
       " (0, 'attack', 62, 68),\n",
       " (0, 'in', 69, 71),\n",
       " (0, 'the', 72, 75),\n",
       " (0, 'Karrada', 76, 83),\n",
       " (0, 'district', 84, 92),\n",
       " (0, 'of', 93, 95),\n",
       " (0, 'Baghdad', 96, 103),\n",
       " (0, '\\n\\n', 103, 105),\n",
       " (1, 'Foreign', 105, 112),\n",
       " (1, 'Office', 113, 119),\n",
       " (1, 'Minister', 120, 128),\n",
       " (1, ',', 128, 129),\n",
       " (1, 'Tobias', 130, 136),\n",
       " (1, 'Ellwood', 137, 144),\n",
       " (1, ',', 144, 145),\n",
       " (1, 'said', 146, 150),\n",
       " (1, ':', 150, 151),\n",
       " (1, '\\n\\n', 151, 153),\n",
       " (1, 'The', 153, 156),\n",
       " (1, 'attack', 157, 163),\n",
       " (1, 'was', 164, 167),\n",
       " (1, 'a', 168, 169),\n",
       " (1, 'horrific', 170, 178),\n",
       " (1, 'act', 179, 182),\n",
       " (1, 'of', 183, 185),\n",
       " (1, 'terror', 186, 192),\n",
       " (1, 'against', 193, 200),\n",
       " (1, 'innocent', 201, 209),\n",
       " (1, 'people', 210, 216),\n",
       " (1, 'in', 217, 219),\n",
       " (1, 'the', 220, 223),\n",
       " (1, 'early', 224, 229),\n",
       " (1, 'hours', 230, 235),\n",
       " (1, 'of', 236, 238),\n",
       " (1, 'Sunday', 239, 245),\n",
       " (1, 'morning', 246, 253),\n",
       " (1, 'in', 254, 256),\n",
       " (1, 'Karrada', 257, 264),\n",
       " (1, ',', 264, 265),\n",
       " (1, 'Baghdad', 266, 273),\n",
       " (1, '.', 273, 274),\n",
       " (2, 'I', 275, 276),\n",
       " (2, 'offer', 277, 282),\n",
       " (2, 'my', 283, 285),\n",
       " (2, 'sincere', 286, 293),\n",
       " (2, 'condolences', 294, 305),\n",
       " (2, 'to', 306, 308),\n",
       " (2, 'the', 309, 312),\n",
       " (2, 'families', 313, 321),\n",
       " (2, 'and', 322, 325),\n",
       " (2, 'friends', 326, 333),\n",
       " (2, 'of', 334, 336),\n",
       " (2, 'the', 337, 340),\n",
       " (2, 'victims', 341, 348),\n",
       " (2, ',', 348, 349),\n",
       " (2, 'and', 350, 353),\n",
       " (2, 'hope', 354, 358),\n",
       " (2, 'those', 359, 364),\n",
       " (2, 'injured', 365, 372),\n",
       " (2, 'in', 373, 375),\n",
       " (2, 'the', 376, 379),\n",
       " (2, 'attack', 380, 386),\n",
       " (2, 'recover', 387, 394),\n",
       " (2, 'quickly', 395, 402),\n",
       " (2, '.', 402, 403),\n",
       " (2, '\\n\\n', 403, 405),\n",
       " (3, 'Daesh', 405, 410),\n",
       " (3, 'targeted', 411, 419),\n",
       " (3, 'families', 420, 428),\n",
       " (3, 'out', 429, 432),\n",
       " (3, 'shopping', 433, 441),\n",
       " (3, 'for', 442, 445),\n",
       " (3, 'Eid', 446, 449),\n",
       " (3, 'and', 450, 453),\n",
       " (3, 'those', 454, 459),\n",
       " (3, 'celebrating', 460, 471),\n",
       " (3, 'suhur', 472, 477),\n",
       " (3, '.', 477, 478),\n",
       " (4, 'It', 479, 481),\n",
       " (4, 'violated', 482, 490),\n",
       " (4, 'the', 491, 494),\n",
       " (4, 'peace', 495, 500),\n",
       " (4, 'of', 501, 503),\n",
       " (4, 'Ramadan', 504, 511),\n",
       " (4, '.', 511, 512),\n",
       " (5, 'The', 513, 516),\n",
       " (5, 'UK', 517, 519),\n",
       " (5, 'stands', 520, 526),\n",
       " (5, 'by', 527, 529),\n",
       " (5, 'Iraq', 530, 534),\n",
       " (5, 'to', 535, 537),\n",
       " (5, 'defeat', 538, 544),\n",
       " (5, 'Daesh', 545, 550),\n",
       " (5, 'and', 551, 554),\n",
       " (5, 'end', 555, 558),\n",
       " (5, 'this', 559, 563),\n",
       " (5, 'violence', 564, 572),\n",
       " (5, '.', 572, 573)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_spans = get_token_spans(document[\"text\"])\n",
    "token_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a data structure to hold the sentence number, token, start index, end index, and labels for each token. Let's define that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Word:\n",
    "    \"\"\"Class for a word and tags\"\"\"\n",
    "\n",
    "    sentence_num: int\n",
    "    word: str\n",
    "    start_idx: int\n",
    "    end_idx: int\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.tags.append(\"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the tokens and their character spans, we can label the words appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_entity(entity: Re3dDict, token_spans: TokenSpan) -> bool:\n",
    "    \"\"\"Check that an Re3d Entity dict's entity span matches a word boundaries.\n",
    "\n",
    "    Some entities in Re3d start inside words, this ensures only entities that align with\n",
    "    word boundaries are valid.\n",
    "\n",
    "    Args:\n",
    "        entity (Re3dDict): Re3d Entity Dictionary\n",
    "        token_spans (TokenSpan): Token spans\n",
    "\n",
    "    Returns:\n",
    "        bool: Valid Entity\n",
    "    \"\"\"\n",
    "    if entity[\"begin\"] not in [tup[2] for tup in token_spans]:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_words(token_spans: TokenSpan, entities: List[Re3dDict]) -> List[Word]:\n",
    "    \"\"\"Label individual words with Re3d entity tags\n",
    "\n",
    "    Args:\n",
    "        token_spans (TokenSpan): Token spans\n",
    "        entities (List[Re3dDict]): List of entities\n",
    "\n",
    "    Returns:\n",
    "        List[Word]: List of Re3d labeled words\n",
    "    \"\"\"\n",
    "    words = []\n",
    "\n",
    "    for sentence_num, text, start_idx, end_idx in token_spans:\n",
    "        word = Word(sentence_num, text, start_idx, end_idx)\n",
    "\n",
    "        for entity in entities:\n",
    "            if not validate_entity(entity, token_spans):\n",
    "                continue\n",
    "\n",
    "            START = entity[\"begin\"]\n",
    "            END = entity[\"end\"]\n",
    "            TYPE = entity[\"type\"]\n",
    "\n",
    "            if START <= word.start_idx <= END and START <= word.end_idx <= END:\n",
    "                if word.tags == [\"O\"]:\n",
    "                    word.tags = []\n",
    "                word.tags.append(TYPE)\n",
    "\n",
    "        words.append(word)\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Word(sentence_num=0, word='Minister', start_idx=0, end_idx=8, tags=['Person']),\n",
       " Word(sentence_num=0, word='for', start_idx=9, end_idx=12, tags=['Person']),\n",
       " Word(sentence_num=0, word='the', start_idx=13, end_idx=16, tags=['Person']),\n",
       " Word(sentence_num=0, word='Middle', start_idx=17, end_idx=23, tags=['Person', 'Location']),\n",
       " Word(sentence_num=0, word='East', start_idx=24, end_idx=28, tags=['Person', 'Location']),\n",
       " Word(sentence_num=0, word=',', start_idx=28, end_idx=29, tags=['O']),\n",
       " Word(sentence_num=0, word='Tobias', start_idx=30, end_idx=36, tags=['Person']),\n",
       " Word(sentence_num=0, word='Ellwood', start_idx=37, end_idx=44, tags=['Person']),\n",
       " Word(sentence_num=0, word=',', start_idx=44, end_idx=45, tags=['O']),\n",
       " Word(sentence_num=0, word='responds', start_idx=46, end_idx=54, tags=['O']),\n",
       " Word(sentence_num=0, word='to', start_idx=55, end_idx=57, tags=['O']),\n",
       " Word(sentence_num=0, word='the', start_idx=58, end_idx=61, tags=['O']),\n",
       " Word(sentence_num=0, word='attack', start_idx=62, end_idx=68, tags=['O']),\n",
       " Word(sentence_num=0, word='in', start_idx=69, end_idx=71, tags=['O']),\n",
       " Word(sentence_num=0, word='the', start_idx=72, end_idx=75, tags=['Location']),\n",
       " Word(sentence_num=0, word='Karrada', start_idx=76, end_idx=83, tags=['Location']),\n",
       " Word(sentence_num=0, word='district', start_idx=84, end_idx=92, tags=['Location']),\n",
       " Word(sentence_num=0, word='of', start_idx=93, end_idx=95, tags=['Location']),\n",
       " Word(sentence_num=0, word='Baghdad', start_idx=96, end_idx=103, tags=['Location', 'Location']),\n",
       " Word(sentence_num=0, word='\\n\\n', start_idx=103, end_idx=105, tags=['O']),\n",
       " Word(sentence_num=1, word='Foreign', start_idx=105, end_idx=112, tags=['Person']),\n",
       " Word(sentence_num=1, word='Office', start_idx=113, end_idx=119, tags=['Person']),\n",
       " Word(sentence_num=1, word='Minister', start_idx=120, end_idx=128, tags=['Person']),\n",
       " Word(sentence_num=1, word=',', start_idx=128, end_idx=129, tags=['O']),\n",
       " Word(sentence_num=1, word='Tobias', start_idx=130, end_idx=136, tags=['Person']),\n",
       " Word(sentence_num=1, word='Ellwood', start_idx=137, end_idx=144, tags=['Person']),\n",
       " Word(sentence_num=1, word=',', start_idx=144, end_idx=145, tags=['O']),\n",
       " Word(sentence_num=1, word='said', start_idx=146, end_idx=150, tags=['O']),\n",
       " Word(sentence_num=1, word=':', start_idx=150, end_idx=151, tags=['O']),\n",
       " Word(sentence_num=1, word='\\n\\n', start_idx=151, end_idx=153, tags=['O']),\n",
       " Word(sentence_num=1, word='The', start_idx=153, end_idx=156, tags=['O']),\n",
       " Word(sentence_num=1, word='attack', start_idx=157, end_idx=163, tags=['O']),\n",
       " Word(sentence_num=1, word='was', start_idx=164, end_idx=167, tags=['O']),\n",
       " Word(sentence_num=1, word='a', start_idx=168, end_idx=169, tags=['O']),\n",
       " Word(sentence_num=1, word='horrific', start_idx=170, end_idx=178, tags=['O']),\n",
       " Word(sentence_num=1, word='act', start_idx=179, end_idx=182, tags=['O']),\n",
       " Word(sentence_num=1, word='of', start_idx=183, end_idx=185, tags=['O']),\n",
       " Word(sentence_num=1, word='terror', start_idx=186, end_idx=192, tags=['O']),\n",
       " Word(sentence_num=1, word='against', start_idx=193, end_idx=200, tags=['O']),\n",
       " Word(sentence_num=1, word='innocent', start_idx=201, end_idx=209, tags=['O']),\n",
       " Word(sentence_num=1, word='people', start_idx=210, end_idx=216, tags=['O']),\n",
       " Word(sentence_num=1, word='in', start_idx=217, end_idx=219, tags=['O']),\n",
       " Word(sentence_num=1, word='the', start_idx=220, end_idx=223, tags=['O']),\n",
       " Word(sentence_num=1, word='early', start_idx=224, end_idx=229, tags=['Temporal']),\n",
       " Word(sentence_num=1, word='hours', start_idx=230, end_idx=235, tags=['Temporal']),\n",
       " Word(sentence_num=1, word='of', start_idx=236, end_idx=238, tags=['Temporal']),\n",
       " Word(sentence_num=1, word='Sunday', start_idx=239, end_idx=245, tags=['Temporal']),\n",
       " Word(sentence_num=1, word='morning', start_idx=246, end_idx=253, tags=['O']),\n",
       " Word(sentence_num=1, word='in', start_idx=254, end_idx=256, tags=['O']),\n",
       " Word(sentence_num=1, word='Karrada', start_idx=257, end_idx=264, tags=['Location']),\n",
       " Word(sentence_num=1, word=',', start_idx=264, end_idx=265, tags=['O']),\n",
       " Word(sentence_num=1, word='Baghdad', start_idx=266, end_idx=273, tags=['Location']),\n",
       " Word(sentence_num=1, word='.', start_idx=273, end_idx=274, tags=['O']),\n",
       " Word(sentence_num=2, word='I', start_idx=275, end_idx=276, tags=['Person']),\n",
       " Word(sentence_num=2, word='offer', start_idx=277, end_idx=282, tags=['O']),\n",
       " Word(sentence_num=2, word='my', start_idx=283, end_idx=285, tags=['O']),\n",
       " Word(sentence_num=2, word='sincere', start_idx=286, end_idx=293, tags=['O']),\n",
       " Word(sentence_num=2, word='condolences', start_idx=294, end_idx=305, tags=['O']),\n",
       " Word(sentence_num=2, word='to', start_idx=306, end_idx=308, tags=['O']),\n",
       " Word(sentence_num=2, word='the', start_idx=309, end_idx=312, tags=['O']),\n",
       " Word(sentence_num=2, word='families', start_idx=313, end_idx=321, tags=['O']),\n",
       " Word(sentence_num=2, word='and', start_idx=322, end_idx=325, tags=['O']),\n",
       " Word(sentence_num=2, word='friends', start_idx=326, end_idx=333, tags=['O']),\n",
       " Word(sentence_num=2, word='of', start_idx=334, end_idx=336, tags=['O']),\n",
       " Word(sentence_num=2, word='the', start_idx=337, end_idx=340, tags=['O']),\n",
       " Word(sentence_num=2, word='victims', start_idx=341, end_idx=348, tags=['O']),\n",
       " Word(sentence_num=2, word=',', start_idx=348, end_idx=349, tags=['O']),\n",
       " Word(sentence_num=2, word='and', start_idx=350, end_idx=353, tags=['O']),\n",
       " Word(sentence_num=2, word='hope', start_idx=354, end_idx=358, tags=['Person']),\n",
       " Word(sentence_num=2, word='those', start_idx=359, end_idx=364, tags=['O']),\n",
       " Word(sentence_num=2, word='injured', start_idx=365, end_idx=372, tags=['O']),\n",
       " Word(sentence_num=2, word='in', start_idx=373, end_idx=375, tags=['O']),\n",
       " Word(sentence_num=2, word='the', start_idx=376, end_idx=379, tags=['O']),\n",
       " Word(sentence_num=2, word='attack', start_idx=380, end_idx=386, tags=['O']),\n",
       " Word(sentence_num=2, word='recover', start_idx=387, end_idx=394, tags=['O']),\n",
       " Word(sentence_num=2, word='quickly', start_idx=395, end_idx=402, tags=['O']),\n",
       " Word(sentence_num=2, word='.', start_idx=402, end_idx=403, tags=['O']),\n",
       " Word(sentence_num=2, word='\\n\\n', start_idx=403, end_idx=405, tags=['O']),\n",
       " Word(sentence_num=3, word='Daesh', start_idx=405, end_idx=410, tags=['Organisation']),\n",
       " Word(sentence_num=3, word='targeted', start_idx=411, end_idx=419, tags=['O']),\n",
       " Word(sentence_num=3, word='families', start_idx=420, end_idx=428, tags=['Organisation']),\n",
       " Word(sentence_num=3, word='out', start_idx=429, end_idx=432, tags=['O']),\n",
       " Word(sentence_num=3, word='shopping', start_idx=433, end_idx=441, tags=['O']),\n",
       " Word(sentence_num=3, word='for', start_idx=442, end_idx=445, tags=['O']),\n",
       " Word(sentence_num=3, word='Eid', start_idx=446, end_idx=449, tags=['O']),\n",
       " Word(sentence_num=3, word='and', start_idx=450, end_idx=453, tags=['O']),\n",
       " Word(sentence_num=3, word='those', start_idx=454, end_idx=459, tags=['O']),\n",
       " Word(sentence_num=3, word='celebrating', start_idx=460, end_idx=471, tags=['O']),\n",
       " Word(sentence_num=3, word='suhur', start_idx=472, end_idx=477, tags=['O']),\n",
       " Word(sentence_num=3, word='.', start_idx=477, end_idx=478, tags=['O']),\n",
       " Word(sentence_num=4, word='It', start_idx=479, end_idx=481, tags=['O']),\n",
       " Word(sentence_num=4, word='violated', start_idx=482, end_idx=490, tags=['O']),\n",
       " Word(sentence_num=4, word='the', start_idx=491, end_idx=494, tags=['O']),\n",
       " Word(sentence_num=4, word='peace', start_idx=495, end_idx=500, tags=['O']),\n",
       " Word(sentence_num=4, word='of', start_idx=501, end_idx=503, tags=['O']),\n",
       " Word(sentence_num=4, word='Ramadan', start_idx=504, end_idx=511, tags=['Temporal']),\n",
       " Word(sentence_num=4, word='.', start_idx=511, end_idx=512, tags=['O']),\n",
       " Word(sentence_num=5, word='The', start_idx=513, end_idx=516, tags=['Organisation']),\n",
       " Word(sentence_num=5, word='UK', start_idx=517, end_idx=519, tags=['Organisation', 'Location']),\n",
       " Word(sentence_num=5, word='stands', start_idx=520, end_idx=526, tags=['O']),\n",
       " Word(sentence_num=5, word='by', start_idx=527, end_idx=529, tags=['O']),\n",
       " Word(sentence_num=5, word='Iraq', start_idx=530, end_idx=534, tags=['Location', 'Organisation']),\n",
       " Word(sentence_num=5, word='to', start_idx=535, end_idx=537, tags=['O']),\n",
       " Word(sentence_num=5, word='defeat', start_idx=538, end_idx=544, tags=['O']),\n",
       " Word(sentence_num=5, word='Daesh', start_idx=545, end_idx=550, tags=['Organisation']),\n",
       " Word(sentence_num=5, word='and', start_idx=551, end_idx=554, tags=['O']),\n",
       " Word(sentence_num=5, word='end', start_idx=555, end_idx=558, tags=['O']),\n",
       " Word(sentence_num=5, word='this', start_idx=559, end_idx=563, tags=['O']),\n",
       " Word(sentence_num=5, word='violence', start_idx=564, end_idx=572, tags=['O']),\n",
       " Word(sentence_num=5, word='.', start_idx=572, end_idx=573, tags=['O'])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = label_words(token_spans, entities)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the Re3d tag schem doesn't organize tags as BIO. We will need to update this for downstream modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def bio_tagger(words: List[Word]) -> List[Word]:\n",
    "    \"\"\"Format Re3d Entity tags into BIO schema\n",
    "\n",
    "    Args:\n",
    "        words (List[Word]): List of Words with Re3d Schema\n",
    "\n",
    "    Returns:\n",
    "        List[Word]: Words with BIO Schema\n",
    "    \"\"\"\n",
    "    max_multilabel_len = max([len(word.tags) for word in words])\n",
    "    words_out = []\n",
    "    prev_tag = [\"O\"] * max_multilabel_len\n",
    "    word_iter = 0\n",
    "    for _, word in enumerate(words):\n",
    "        bio_tagged = []\n",
    "        _, labels = deepcopy(word.word), deepcopy(word.tags)\n",
    "\n",
    "        for idx, label in enumerate(labels):\n",
    "            if label == \"O\":\n",
    "                bio_tagged.append(label)\n",
    "            elif label != \"O\" and prev_tag[idx] == \"O\":  # Begin NE\n",
    "                bio_tagged.append(\"B-\" + label)\n",
    "            elif prev_tag[idx] != \"O\" and prev_tag[idx] == label:  # Inside NE\n",
    "                bio_tagged.append(\"I-\" + label)\n",
    "            elif prev_tag[idx] != \"O\" and prev_tag[idx] != label:  # Adjacent NE\n",
    "                bio_tagged.append(\"B-\" + label)\n",
    "            prev_tag[idx] = label\n",
    "\n",
    "        # Reset secondary/tertiary labels if no extra labels\n",
    "        if len(labels) > 1:\n",
    "            word_iter += 1\n",
    "            if word_iter > 1:\n",
    "                for idx in range(1, len(prev_tag)):\n",
    "                    prev_tag[idx] = \"O\"\n",
    "                word_iter = 0\n",
    "\n",
    "        word.tags = bio_tagged\n",
    "\n",
    "        words_out.append(word)\n",
    "\n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Word(sentence_num=0, word='Minister', start_idx=0, end_idx=8, tags=['B-Person']),\n",
       " Word(sentence_num=0, word='for', start_idx=9, end_idx=12, tags=['I-Person']),\n",
       " Word(sentence_num=0, word='the', start_idx=13, end_idx=16, tags=['I-Person']),\n",
       " Word(sentence_num=0, word='Middle', start_idx=17, end_idx=23, tags=['I-Person', 'B-Location']),\n",
       " Word(sentence_num=0, word='East', start_idx=24, end_idx=28, tags=['I-Person', 'I-Location']),\n",
       " Word(sentence_num=0, word=',', start_idx=28, end_idx=29, tags=['O']),\n",
       " Word(sentence_num=0, word='Tobias', start_idx=30, end_idx=36, tags=['B-Person']),\n",
       " Word(sentence_num=0, word='Ellwood', start_idx=37, end_idx=44, tags=['I-Person']),\n",
       " Word(sentence_num=0, word=',', start_idx=44, end_idx=45, tags=['O']),\n",
       " Word(sentence_num=0, word='responds', start_idx=46, end_idx=54, tags=['O']),\n",
       " Word(sentence_num=0, word='to', start_idx=55, end_idx=57, tags=['O']),\n",
       " Word(sentence_num=0, word='the', start_idx=58, end_idx=61, tags=['O']),\n",
       " Word(sentence_num=0, word='attack', start_idx=62, end_idx=68, tags=['O']),\n",
       " Word(sentence_num=0, word='in', start_idx=69, end_idx=71, tags=['O']),\n",
       " Word(sentence_num=0, word='the', start_idx=72, end_idx=75, tags=['B-Location']),\n",
       " Word(sentence_num=0, word='Karrada', start_idx=76, end_idx=83, tags=['I-Location']),\n",
       " Word(sentence_num=0, word='district', start_idx=84, end_idx=92, tags=['I-Location']),\n",
       " Word(sentence_num=0, word='of', start_idx=93, end_idx=95, tags=['I-Location']),\n",
       " Word(sentence_num=0, word='Baghdad', start_idx=96, end_idx=103, tags=['I-Location', 'B-Location']),\n",
       " Word(sentence_num=0, word='\\n\\n', start_idx=103, end_idx=105, tags=['O']),\n",
       " Word(sentence_num=1, word='Foreign', start_idx=105, end_idx=112, tags=['B-Person']),\n",
       " Word(sentence_num=1, word='Office', start_idx=113, end_idx=119, tags=['I-Person']),\n",
       " Word(sentence_num=1, word='Minister', start_idx=120, end_idx=128, tags=['I-Person']),\n",
       " Word(sentence_num=1, word=',', start_idx=128, end_idx=129, tags=['O']),\n",
       " Word(sentence_num=1, word='Tobias', start_idx=130, end_idx=136, tags=['B-Person']),\n",
       " Word(sentence_num=1, word='Ellwood', start_idx=137, end_idx=144, tags=['I-Person']),\n",
       " Word(sentence_num=1, word=',', start_idx=144, end_idx=145, tags=['O']),\n",
       " Word(sentence_num=1, word='said', start_idx=146, end_idx=150, tags=['O']),\n",
       " Word(sentence_num=1, word=':', start_idx=150, end_idx=151, tags=['O']),\n",
       " Word(sentence_num=1, word='\\n\\n', start_idx=151, end_idx=153, tags=['O']),\n",
       " Word(sentence_num=1, word='The', start_idx=153, end_idx=156, tags=['O']),\n",
       " Word(sentence_num=1, word='attack', start_idx=157, end_idx=163, tags=['O']),\n",
       " Word(sentence_num=1, word='was', start_idx=164, end_idx=167, tags=['O']),\n",
       " Word(sentence_num=1, word='a', start_idx=168, end_idx=169, tags=['O']),\n",
       " Word(sentence_num=1, word='horrific', start_idx=170, end_idx=178, tags=['O']),\n",
       " Word(sentence_num=1, word='act', start_idx=179, end_idx=182, tags=['O']),\n",
       " Word(sentence_num=1, word='of', start_idx=183, end_idx=185, tags=['O']),\n",
       " Word(sentence_num=1, word='terror', start_idx=186, end_idx=192, tags=['O']),\n",
       " Word(sentence_num=1, word='against', start_idx=193, end_idx=200, tags=['O']),\n",
       " Word(sentence_num=1, word='innocent', start_idx=201, end_idx=209, tags=['O']),\n",
       " Word(sentence_num=1, word='people', start_idx=210, end_idx=216, tags=['O']),\n",
       " Word(sentence_num=1, word='in', start_idx=217, end_idx=219, tags=['O']),\n",
       " Word(sentence_num=1, word='the', start_idx=220, end_idx=223, tags=['O']),\n",
       " Word(sentence_num=1, word='early', start_idx=224, end_idx=229, tags=['B-Temporal']),\n",
       " Word(sentence_num=1, word='hours', start_idx=230, end_idx=235, tags=['I-Temporal']),\n",
       " Word(sentence_num=1, word='of', start_idx=236, end_idx=238, tags=['I-Temporal']),\n",
       " Word(sentence_num=1, word='Sunday', start_idx=239, end_idx=245, tags=['I-Temporal']),\n",
       " Word(sentence_num=1, word='morning', start_idx=246, end_idx=253, tags=['O']),\n",
       " Word(sentence_num=1, word='in', start_idx=254, end_idx=256, tags=['O']),\n",
       " Word(sentence_num=1, word='Karrada', start_idx=257, end_idx=264, tags=['B-Location']),\n",
       " Word(sentence_num=1, word=',', start_idx=264, end_idx=265, tags=['O']),\n",
       " Word(sentence_num=1, word='Baghdad', start_idx=266, end_idx=273, tags=['B-Location']),\n",
       " Word(sentence_num=1, word='.', start_idx=273, end_idx=274, tags=['O']),\n",
       " Word(sentence_num=2, word='I', start_idx=275, end_idx=276, tags=['B-Person']),\n",
       " Word(sentence_num=2, word='offer', start_idx=277, end_idx=282, tags=['O']),\n",
       " Word(sentence_num=2, word='my', start_idx=283, end_idx=285, tags=['O']),\n",
       " Word(sentence_num=2, word='sincere', start_idx=286, end_idx=293, tags=['O']),\n",
       " Word(sentence_num=2, word='condolences', start_idx=294, end_idx=305, tags=['O']),\n",
       " Word(sentence_num=2, word='to', start_idx=306, end_idx=308, tags=['O']),\n",
       " Word(sentence_num=2, word='the', start_idx=309, end_idx=312, tags=['O']),\n",
       " Word(sentence_num=2, word='families', start_idx=313, end_idx=321, tags=['O']),\n",
       " Word(sentence_num=2, word='and', start_idx=322, end_idx=325, tags=['O']),\n",
       " Word(sentence_num=2, word='friends', start_idx=326, end_idx=333, tags=['O']),\n",
       " Word(sentence_num=2, word='of', start_idx=334, end_idx=336, tags=['O']),\n",
       " Word(sentence_num=2, word='the', start_idx=337, end_idx=340, tags=['O']),\n",
       " Word(sentence_num=2, word='victims', start_idx=341, end_idx=348, tags=['O']),\n",
       " Word(sentence_num=2, word=',', start_idx=348, end_idx=349, tags=['O']),\n",
       " Word(sentence_num=2, word='and', start_idx=350, end_idx=353, tags=['O']),\n",
       " Word(sentence_num=2, word='hope', start_idx=354, end_idx=358, tags=['B-Person']),\n",
       " Word(sentence_num=2, word='those', start_idx=359, end_idx=364, tags=['O']),\n",
       " Word(sentence_num=2, word='injured', start_idx=365, end_idx=372, tags=['O']),\n",
       " Word(sentence_num=2, word='in', start_idx=373, end_idx=375, tags=['O']),\n",
       " Word(sentence_num=2, word='the', start_idx=376, end_idx=379, tags=['O']),\n",
       " Word(sentence_num=2, word='attack', start_idx=380, end_idx=386, tags=['O']),\n",
       " Word(sentence_num=2, word='recover', start_idx=387, end_idx=394, tags=['O']),\n",
       " Word(sentence_num=2, word='quickly', start_idx=395, end_idx=402, tags=['O']),\n",
       " Word(sentence_num=2, word='.', start_idx=402, end_idx=403, tags=['O']),\n",
       " Word(sentence_num=2, word='\\n\\n', start_idx=403, end_idx=405, tags=['O']),\n",
       " Word(sentence_num=3, word='Daesh', start_idx=405, end_idx=410, tags=['B-Organisation']),\n",
       " Word(sentence_num=3, word='targeted', start_idx=411, end_idx=419, tags=['O']),\n",
       " Word(sentence_num=3, word='families', start_idx=420, end_idx=428, tags=['B-Organisation']),\n",
       " Word(sentence_num=3, word='out', start_idx=429, end_idx=432, tags=['O']),\n",
       " Word(sentence_num=3, word='shopping', start_idx=433, end_idx=441, tags=['O']),\n",
       " Word(sentence_num=3, word='for', start_idx=442, end_idx=445, tags=['O']),\n",
       " Word(sentence_num=3, word='Eid', start_idx=446, end_idx=449, tags=['O']),\n",
       " Word(sentence_num=3, word='and', start_idx=450, end_idx=453, tags=['O']),\n",
       " Word(sentence_num=3, word='those', start_idx=454, end_idx=459, tags=['O']),\n",
       " Word(sentence_num=3, word='celebrating', start_idx=460, end_idx=471, tags=['O']),\n",
       " Word(sentence_num=3, word='suhur', start_idx=472, end_idx=477, tags=['O']),\n",
       " Word(sentence_num=3, word='.', start_idx=477, end_idx=478, tags=['O']),\n",
       " Word(sentence_num=4, word='It', start_idx=479, end_idx=481, tags=['O']),\n",
       " Word(sentence_num=4, word='violated', start_idx=482, end_idx=490, tags=['O']),\n",
       " Word(sentence_num=4, word='the', start_idx=491, end_idx=494, tags=['O']),\n",
       " Word(sentence_num=4, word='peace', start_idx=495, end_idx=500, tags=['O']),\n",
       " Word(sentence_num=4, word='of', start_idx=501, end_idx=503, tags=['O']),\n",
       " Word(sentence_num=4, word='Ramadan', start_idx=504, end_idx=511, tags=['B-Temporal']),\n",
       " Word(sentence_num=4, word='.', start_idx=511, end_idx=512, tags=['O']),\n",
       " Word(sentence_num=5, word='The', start_idx=513, end_idx=516, tags=['B-Organisation']),\n",
       " Word(sentence_num=5, word='UK', start_idx=517, end_idx=519, tags=['I-Organisation', 'I-Location']),\n",
       " Word(sentence_num=5, word='stands', start_idx=520, end_idx=526, tags=['O']),\n",
       " Word(sentence_num=5, word='by', start_idx=527, end_idx=529, tags=['O']),\n",
       " Word(sentence_num=5, word='Iraq', start_idx=530, end_idx=534, tags=['B-Location', 'B-Organisation']),\n",
       " Word(sentence_num=5, word='to', start_idx=535, end_idx=537, tags=['O']),\n",
       " Word(sentence_num=5, word='defeat', start_idx=538, end_idx=544, tags=['O']),\n",
       " Word(sentence_num=5, word='Daesh', start_idx=545, end_idx=550, tags=['B-Organisation']),\n",
       " Word(sentence_num=5, word='and', start_idx=551, end_idx=554, tags=['O']),\n",
       " Word(sentence_num=5, word='end', start_idx=555, end_idx=558, tags=['O']),\n",
       " Word(sentence_num=5, word='this', start_idx=559, end_idx=563, tags=['O']),\n",
       " Word(sentence_num=5, word='violence', start_idx=564, end_idx=572, tags=['O']),\n",
       " Word(sentence_num=5, word='.', start_idx=572, end_idx=573, tags=['O'])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_tagger(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the words tagged in the BIO schema, we need to compile the words across the entire Re3d dataset. Outined below is the process for a single set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_doc_id(doc: Re3dDict, line: Re3dDict) -> bool:\n",
    "    \"\"\"Match entities to document by document ID\n",
    "\n",
    "    Args:\n",
    "        doc (Re3dDict): Re3d Document dictionary\n",
    "        line (Re3dDict): Re3d Entity dictionary\n",
    "\n",
    "    Returns:\n",
    "        bool: True if document id matches between arguments\n",
    "    \"\"\"\n",
    "    return doc[\"_id\"] == line[\"documentId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_docs(doc_path: Path) -> List[pd.DataFrame]:\n",
    "    \"\"\"ETL a given documents.json into a dataframe with sentence number,\n",
    "    word, start index, end index, and BIO tags\n",
    "\n",
    "    Args:\n",
    "        doc_path (Path): Path to */documents.json\n",
    "\n",
    "    Returns:\n",
    "        List[pd.DataFrame]: Dataframe for each document in doc_path\n",
    "    \"\"\"\n",
    "    # load docs\n",
    "    with open(doc_path, \"r\") as fp:\n",
    "        docs = [literal_eval(line) for line in fp]\n",
    "\n",
    "    entities_path = doc_path.parent / \"entities.json\"\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for doc in docs:\n",
    "        # Load entities for doc\n",
    "        with open(entities_path, \"r\") as fp:\n",
    "            entities = [literal_eval(line) for line in fp if match_doc_id(doc, literal_eval(line))]\n",
    "\n",
    "        # ID sentence number, token, start/end idx\n",
    "        token_spans = get_token_spans(doc[\"text\"])\n",
    "\n",
    "        # Add tags\n",
    "        labeled_words = label_words(token_spans, entities)\n",
    "\n",
    "        # Format tags as BIO\n",
    "        tagged_words = bio_tagger(labeled_words)\n",
    "\n",
    "        # Create dataframe\n",
    "        doc_df = pd.DataFrame(tagged_words)\n",
    "\n",
    "        output.append(doc_df)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = preprocess_docs(Path(\"/home/enyquist/repos/RLNER/data/raw/Australian Department of Foreign Affairs/documents.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(dfs: List[List[pd.DataFrame]]) -> pd.DataFrame:\n",
    "    \"\"\"Merge nested lists of dataframes into one dataframe\n",
    "\n",
    "    Args:\n",
    "        dfs (List[List[pd.DataFrame]]): Nested dataframes\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Merged dataframe\n",
    "    \"\"\"\n",
    "    flat_dfs = [item for sublist in dfs for item in sublist]\n",
    "    base_df = flat_dfs.pop()\n",
    "\n",
    "    while flat_dfs:\n",
    "        df = flat_dfs.pop()\n",
    "        max_sentence_num = max(base_df[\"sentence_num\"])\n",
    "        df[\"sentence_num\"] = df[\"sentence_num\"].apply(lambda x: x + max_sentence_num + 1)\n",
    "        base_df = pd.concat([base_df, df], axis=0)\n",
    "\n",
    "    return base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = merge_dfs([dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>word</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[B-Person]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Minister</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>[I-Person]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Julie</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>[I-Person, B-Person]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Bishop</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>[I-Person, I-Person]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>met</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>15</td>\n",
       "      <td>in</td>\n",
       "      <td>939</td>\n",
       "      <td>941</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>15</td>\n",
       "      <td>particular</td>\n",
       "      <td>942</td>\n",
       "      <td>952</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>15</td>\n",
       "      <td>against</td>\n",
       "      <td>953</td>\n",
       "      <td>960</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>15</td>\n",
       "      <td>ISIL</td>\n",
       "      <td>961</td>\n",
       "      <td>965</td>\n",
       "      <td>[B-Organisation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>15</td>\n",
       "      <td>.</td>\n",
       "      <td>965</td>\n",
       "      <td>966</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_num        word  start_idx  end_idx                  tags\n",
       "0               0     Foreign          0        7            [B-Person]\n",
       "1               0    Minister          8       16            [I-Person]\n",
       "2               0       Julie         17       22  [I-Person, B-Person]\n",
       "3               0      Bishop         23       29  [I-Person, I-Person]\n",
       "4               0         met         30       33                   [O]\n",
       "..            ...         ...        ...      ...                   ...\n",
       "383            15          in        939      941                   [O]\n",
       "384            15  particular        942      952                   [O]\n",
       "385            15     against        953      960                   [O]\n",
       "386            15        ISIL        961      965      [B-Organisation]\n",
       "387            15           .        965      966                   [O]\n",
       "\n",
       "[388 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs_df[\"tags\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def add_pos_tag(x):\n",
    "    doc = nlp(x)\n",
    "    return [tok.pos_ for tok in doc][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df[\"single_tag\"] = docs_df[\"tags\"].apply(lambda x: x[0])\n",
    "docs_df[\"POS\"] = docs_df[\"word\"].apply(add_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>word</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>tags</th>\n",
       "      <th>single_tag</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[B-Person]</td>\n",
       "      <td>B-Person</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Minister</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>[I-Person]</td>\n",
       "      <td>I-Person</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Julie</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>[I-Person, B-Person]</td>\n",
       "      <td>I-Person</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Bishop</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>[I-Person, I-Person]</td>\n",
       "      <td>I-Person</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>met</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_num      word  start_idx  end_idx                  tags  \\\n",
       "0             0   Foreign          0        7            [B-Person]   \n",
       "1             0  Minister          8       16            [I-Person]   \n",
       "2             0     Julie         17       22  [I-Person, B-Person]   \n",
       "3             0    Bishop         23       29  [I-Person, I-Person]   \n",
       "4             0       met         30       33                   [O]   \n",
       "\n",
       "  single_tag    POS  \n",
       "0   B-Person    ADJ  \n",
       "1   I-Person  PROPN  \n",
       "2   I-Person  PROPN  \n",
       "3   I-Person  PROPN  \n",
       "4          O   VERB  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Transform raw Re3d Data into a master csv\"\"\"\n",
    "\n",
    "    docs_list = list(RAW_DIR.glob(\"**/documents.json\"))\n",
    "\n",
    "    # Process docs\n",
    "    dfs = [preprocess_docs(doc_path) for doc_path in tqdm(docs_list, desc=\"Formatting Doc Paths\")]\n",
    "\n",
    "    # Merge docs\n",
    "    master_df = merge_dfs(dfs)\n",
    "    master_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Split single labels out instead of multi-label\n",
    "    master_df[\"single_tag\"] = master_df[\"tags\"].apply(lambda x: x[0])\n",
    "    master_df[\"POS\"] = master_df[\"word\"].apply(add_pos_tag)\n",
    "\n",
    "    # Save master df\n",
    "    master_df.to_csv(PREPARED_DIR / \"master.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1566ea1af4a47ca7acc671ba85a809484c1db5e7319af0d3caf0750117059574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
