{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Bi-LSTM CRF\"></a>\n",
    "\n",
    "# Bi-LSTM CRF Model\n",
    "\n",
    "We will leverage a Bi-LSTM CRF model as the baseline tagger.\n",
    "\n",
    "This notebook explores the construction of the tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path('notebooks/eda.ipynb').resolve().parents[2]\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "PREPARED_DIR = DATA_DIR / \"prepared\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>word</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>tags</th>\n",
       "      <th>single_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[B-Temporal]</td>\n",
       "      <td>B-Temporal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>week</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>[I-Temporal]</td>\n",
       "      <td>I-Temporal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sees</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>start</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_num   word  start_idx  end_idx          tags  single_tag\n",
       "0             0   This          0        4  [B-Temporal]  B-Temporal\n",
       "1             0   week          5        9  [I-Temporal]  I-Temporal\n",
       "2             0   sees         10       14           [O]           O\n",
       "3             0    the         15       18           [O]           O\n",
       "4             0  start         19       24           [O]           O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "df = pd.read_csv(PREPARED_DIR / \"master.csv\")\n",
    "df[\"tags\"] = df[\"tags\"].apply(literal_eval)\n",
    "df[\"single_tag\"] = df[\"tags\"].apply(lambda x: x[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4332 unique words\n"
     ]
    }
   ],
   "source": [
    "words = set(list(df['word'].values))\n",
    "words.add('PADword')\n",
    "n_words = len(words)\n",
    "print(f\"There are {n_words} unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 unique tags\n"
     ]
    }
   ],
   "source": [
    "tags = list(set(df[\"single_tag\"].values))\n",
    "n_tags = len(tags)\n",
    "print(f\"There are {n_tags} unique tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter:\n",
    "    \"\"\"Iterator to get a sentence sequence and its BIO tags\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"].values.tolist(),s[\"single_tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence_num\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[self.n_sent]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1013 total sentence\n"
     ]
    }
   ],
   "source": [
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences\n",
    "print(f\"There are {len(sentences)} total sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make indices for ML modeling\n",
    "words2index = {w:i for i,w in enumerate(words)}\n",
    "tags2index = {t:i for i,t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "max_len = 50\n",
    "y = [[tags2index[w[1]] for w in s] for s in sentences]\n",
    "\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tags2index[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1013, 50)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "X = [[words2index[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 10:27:19.552134: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "2022-11-10 10:27:19.552182: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: enyquist-X399-DESIGNARE-EX\n",
      "2022-11-10 10:27:19.552193: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: enyquist-X399-DESIGNARE-EX\n",
      "2022-11-10 10:27:19.552360: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.85.2\n",
      "2022-11-10 10:27:19.552391: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5\n",
      "2022-11-10 10:27:19.552400: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 520.61.5 does not match DSO version 510.85.2 -- cannot find working devices in this configuration\n",
      "2022-11-10 10:27:19.553048: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_tensor = tf.convert_to_tensor(X)\n",
    "y_tensor = tf.convert_to_tensor(y)\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((x_tensor, y_tensor))\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(\n",
    "    ds, \n",
    "    ds_size, \n",
    "    train_split=0.8, \n",
    "    val_split=0.1, \n",
    "    test_split=0.1, \n",
    "    shuffle=True, \n",
    "    shuffle_size=1000\n",
    "):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=42)\n",
    "\n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds.batch(BATCH_SIZE), val_ds.batch(BATCH_SIZE), test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(\n",
    "    ds=ds,\n",
    "    ds_size=X.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow_addons.text import crf_log_likelihood, crf_decode\n",
    "\n",
    "\"\"\"\n",
    "Credit:\n",
    "https://github.com/ngoquanghuy99/POS-Tagging-BiLSTM-CRF\n",
    "\"\"\"\n",
    "\n",
    "class CRF(L.Layer):\n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 sparse_target=True,\n",
    "                 **kwargs):\n",
    "        \"\"\"    \n",
    "        Args:\n",
    "            output_dim (int): the number of labels to tag each temporal input.\n",
    "            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n",
    "        Input shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        Output shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        \"\"\"\n",
    "        super(CRF, self).__init__(**kwargs)\n",
    "        self.output_dim = int(output_dim) \n",
    "        self.sparse_target = sparse_target\n",
    "        self.input_spec = L.InputSpec(min_ndim=3)\n",
    "        self.supports_masking = False\n",
    "        self.sequence_lengths = None\n",
    "        self.transitions = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        f_shape = tf.TensorShape(input_shape)\n",
    "        input_spec = L.InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n",
    "\n",
    "        if f_shape[-1] is None:\n",
    "            raise ValueError('The last dimension of the inputs to `CRF` '\n",
    "                             'should be defined. Found `None`.')\n",
    "        if f_shape[-1] != self.output_dim:\n",
    "            raise ValueError('The last dimension of the input shape must be equal to output'\n",
    "                             ' shape. Use a linear layer if needed.')\n",
    "        self.input_spec = input_spec\n",
    "        self.transitions = self.add_weight(name='transitions',\n",
    "                                           shape=[self.output_dim, self.output_dim],\n",
    "                                           initializer='glorot_uniform',\n",
    "                                           trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Just pass the received mask from previous layer, to the next layer or\n",
    "        # manipulate it if this layer changes the shape of the input\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n",
    "        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n",
    "        if sequence_lengths is not None:\n",
    "            assert len(sequence_lengths.shape) == 2\n",
    "            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n",
    "            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n",
    "            assert seq_len_shape[1] == 1\n",
    "            self.sequence_lengths = K.flatten(sequence_lengths)\n",
    "        else:\n",
    "            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n",
    "                tf.shape(inputs)[1]\n",
    "            )\n",
    "\n",
    "        viterbi_sequence, _ = crf_decode(sequences,\n",
    "                                         self.transitions,\n",
    "                                         self.sequence_lengths)\n",
    "        output = K.one_hot(viterbi_sequence, self.output_dim)\n",
    "        return K.in_train_phase(sequences, output)\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        def crf_loss(y_true, y_pred):\n",
    "            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
    "            log_likelihood, self.transitions = crf_log_likelihood(\n",
    "                y_pred,\n",
    "                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
    "                self.sequence_lengths,\n",
    "                transition_params=self.transitions,\n",
    "            )\n",
    "            return tf.reduce_mean(-log_likelihood)\n",
    "        return crf_loss\n",
    "\n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        def viterbi_accuracy(y_true, y_pred):\n",
    "            # -1e10 to avoid zero at sum(mask)\n",
    "            mask = K.cast(\n",
    "                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
    "            shape = tf.shape(y_pred)\n",
    "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "            if self.sparse_target:\n",
    "                y_true = K.argmax(y_true, 2)\n",
    "            y_pred = K.cast(y_pred, 'int32')\n",
    "            y_true = K.cast(y_true, 'int32')\n",
    "            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
    "            return K.sum(corrects * mask) / K.sum(mask)\n",
    "        return viterbi_accuracy\n",
    "\n",
    "    @property\n",
    "    def f1(self):\n",
    "        def crf_f1(y_true, y_pred):\n",
    "            shape = tf.shape(y_pred)\n",
    "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "            true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "            possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "            predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "            precision = true_positives / (predicted_positives + K.epsilon())\n",
    "            recall = true_positives / (possible_positives + K.epsilon())\n",
    "            f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "            return f1_val\n",
    "        return crf_f1\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        tf.TensorShape(input_shape).assert_has_rank(3)\n",
    "        return input_shape[:2] + (self.output_dim,)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'sparse_target': self.sparse_target,\n",
    "            'supports_masking': self.supports_masking,\n",
    "            'transitions': K.eval(self.transitions)\n",
    "        }\n",
    "        base_config = super(CRF, self).get_config()\n",
    "        return dict(base_config, **config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIR = DATA_DIR / \"embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Credit:\n",
    "https://github.com/ngoquanghuy99/POS-Tagging-BiLSTM-CRF\n",
    "\"\"\"\n",
    "\n",
    "def create_model(\n",
    "    vocab_size,\n",
    "    max_length,\n",
    "    embedding_dim,\n",
    "    word_index,\n",
    "    tag_index\n",
    "):\n",
    "\n",
    "    embeddings_index = {}\n",
    "    with io.open(EMBEDDING_DIR / 'glove.6B.100d.txt', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            curr_word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float64')\n",
    "            embeddings_index[curr_word] = coefs\n",
    "        embeddings_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "        for word, i in word_index.items():\n",
    "            if i > vocab_size:\n",
    "                continue\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embeddings_matrix[i] = embedding_vector\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            input_length=max_length,\n",
    "            weights=[embeddings_matrix],\n",
    "            mask_zero=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                units=embedding_dim, return_sequences=True, recurrent_dropout=0.01\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(len(tag_index))))\n",
    "\n",
    "    crf = CRF(len(tag_index), sparse_target=False)\n",
    "    model.add(crf)\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=crf.loss, metrics=[crf.accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 100)           433200    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 50, 200)          160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 50, 29)           5829      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " crf (CRF)                   (None, 50, 29)            841       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600,670\n",
      "Trainable params: 600,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(\n",
    "    vocab_size=len(words2index),\n",
    "    max_length=50,\n",
    "    embedding_dim=100,\n",
    "    word_index=words2index,\n",
    "    tag_index=tags2index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "log_dir = ROOT_DIR / \"models/logs/\"\n",
    "\n",
    "if any(log_dir.iterdir()):\n",
    "    for i in log_dir.glob(\"**/*\"):\n",
    "        if i.is_dir():\n",
    "            shutil.rmtree(i)\n",
    "        else:\n",
    "            i.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 10:29:56.585248: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-10 10:29:56.585293: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-10 10:29:56.586009: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-10 10:29:56.616318: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-11-10 10:29:56.616352: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-11-10 10:30:01.030429: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'crf_loss/cond/output/_845'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 9s 191ms/step - loss: 128.2678 - viterbi_accuracy: 0.5286 - val_loss: 139.7882 - val_viterbi_accuracy: 0.4347\n",
      "Epoch 2/100\n",
      " 6/13 [============>.................] - ETA: 0s - loss: 54.5011 - viterbi_accuracy: 0.8465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 10:30:06.553633: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-10 10:30:08.538850: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-11-10 10:30:11.627919: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /home/enyquist/repos/RLNER/models/logs/plugins/profile/2022_11_10_10_30_08\n",
      "\n",
      "2022-11-10 10:30:14.725803: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to /home/enyquist/repos/RLNER/models/logs/plugins/profile/2022_11_10_10_30_08/enyquist-X399-DESIGNARE-EX.trace.json.gz\n",
      "2022-11-10 10:30:16.174196: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /home/enyquist/repos/RLNER/models/logs/plugins/profile/2022_11_10_10_30_08\n",
      "\n",
      "2022-11-10 10:30:16.174331: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to /home/enyquist/repos/RLNER/models/logs/plugins/profile/2022_11_10_10_30_08/enyquist-X399-DESIGNARE-EX.memory_profile.json.gz\n",
      "2022-11-10 10:30:16.200313: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /home/enyquist/repos/RLNER/models/logs/plugins/profile/2022_11_10_10_30_08\n",
      "Dumped tool data for xplane.pb to /home/enyquist/repos/RLNER/models/logs/plugins/profile/2022_11_10_10_30_08/enyquist-X399-DESIGNARE-EX.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /home/enyquist/repos/RLNER/models/logs/plugins/profile/2022_11_10_10_30_08/enyquist-X399-DESIGNARE-EX.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /home/enyquist/repos/RLNER/models/logs/plugins/profile/2022_11_10_10_30_08/enyquist-X399-DESIGNARE-EX.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /home/enyquist/repos/RLNER/models/logs/plugins/profile/2022_11_10_10_30_08/enyquist-X399-DESIGNARE-EX.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /home/enyquist/repos/RLNER/models/logs/plugins/profile/2022_11_10_10_30_08/enyquist-X399-DESIGNARE-EX.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 12s 991ms/step - loss: 49.0816 - viterbi_accuracy: 0.8460 - val_loss: 139.0940 - val_viterbi_accuracy: 0.4413\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 40.6658 - viterbi_accuracy: 0.8377 - val_loss: 138.6207 - val_viterbi_accuracy: 0.4368\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 35.6045 - viterbi_accuracy: 0.8443 - val_loss: 138.8639 - val_viterbi_accuracy: 0.4397\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 33.0754 - viterbi_accuracy: 0.8438 - val_loss: 138.1800 - val_viterbi_accuracy: 0.8336\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 29.7640 - viterbi_accuracy: 0.8488 - val_loss: 137.8049 - val_viterbi_accuracy: 0.8417\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 28.0674 - viterbi_accuracy: 0.8490 - val_loss: 136.9574 - val_viterbi_accuracy: 0.8660\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 25.2815 - viterbi_accuracy: 0.8603 - val_loss: 136.7509 - val_viterbi_accuracy: 0.8640\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 23.6938 - viterbi_accuracy: 0.8641 - val_loss: 136.2014 - val_viterbi_accuracy: 0.8674\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 21.3948 - viterbi_accuracy: 0.8795 - val_loss: 135.2238 - val_viterbi_accuracy: 0.8899\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 19.4260 - viterbi_accuracy: 0.8903 - val_loss: 134.9215 - val_viterbi_accuracy: 0.8836\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 18.7042 - viterbi_accuracy: 0.8937 - val_loss: 134.4404 - val_viterbi_accuracy: 0.8893\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 16.6480 - viterbi_accuracy: 0.9048 - val_loss: 133.2417 - val_viterbi_accuracy: 0.9214\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 16.0765 - viterbi_accuracy: 0.9089 - val_loss: 132.9423 - val_viterbi_accuracy: 0.9179\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 14.5154 - viterbi_accuracy: 0.9187 - val_loss: 132.9990 - val_viterbi_accuracy: 0.9216\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 13.6192 - viterbi_accuracy: 0.9238 - val_loss: 132.3667 - val_viterbi_accuracy: 0.9214\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 12.8139 - viterbi_accuracy: 0.9276 - val_loss: 132.3314 - val_viterbi_accuracy: 0.9161\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 11.9983 - viterbi_accuracy: 0.9317 - val_loss: 131.5502 - val_viterbi_accuracy: 0.9421\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 11.1017 - viterbi_accuracy: 0.9375 - val_loss: 131.2608 - val_viterbi_accuracy: 0.9462\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 10.7934 - viterbi_accuracy: 0.9372 - val_loss: 131.0212 - val_viterbi_accuracy: 0.9425\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 10.3149 - viterbi_accuracy: 0.9397 - val_loss: 130.5778 - val_viterbi_accuracy: 0.9586\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 9.4362 - viterbi_accuracy: 0.9451 - val_loss: 130.1290 - val_viterbi_accuracy: 0.9511\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 8.8301 - viterbi_accuracy: 0.9486 - val_loss: 130.2705 - val_viterbi_accuracy: 0.9466\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 8.8373 - viterbi_accuracy: 0.9461 - val_loss: 130.0415 - val_viterbi_accuracy: 0.9557\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 7.8166 - viterbi_accuracy: 0.9530 - val_loss: 130.3718 - val_viterbi_accuracy: 0.9421\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 7.4154 - viterbi_accuracy: 0.9550 - val_loss: 129.9287 - val_viterbi_accuracy: 0.9503\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 7.1903 - viterbi_accuracy: 0.9572 - val_loss: 129.4351 - val_viterbi_accuracy: 0.9572\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 6.6302 - viterbi_accuracy: 0.9600 - val_loss: 128.6882 - val_viterbi_accuracy: 0.9611\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 6.7258 - viterbi_accuracy: 0.9590 - val_loss: 128.8159 - val_viterbi_accuracy: 0.9649\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 5.9554 - viterbi_accuracy: 0.9649 - val_loss: 128.5474 - val_viterbi_accuracy: 0.9593\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 5.5553 - viterbi_accuracy: 0.9673 - val_loss: 128.7396 - val_viterbi_accuracy: 0.9697\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 5.4575 - viterbi_accuracy: 0.9678 - val_loss: 128.1750 - val_viterbi_accuracy: 0.9710\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 5.0556 - viterbi_accuracy: 0.9698 - val_loss: 127.8620 - val_viterbi_accuracy: 0.9733\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 4.9468 - viterbi_accuracy: 0.9717 - val_loss: 127.4563 - val_viterbi_accuracy: 0.9704\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 4.6813 - viterbi_accuracy: 0.9730 - val_loss: 128.2222 - val_viterbi_accuracy: 0.9695\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 4.3871 - viterbi_accuracy: 0.9742 - val_loss: 127.7266 - val_viterbi_accuracy: 0.9743\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 4.2885 - viterbi_accuracy: 0.9756 - val_loss: 127.4386 - val_viterbi_accuracy: 0.9749\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 3.9246 - viterbi_accuracy: 0.9780 - val_loss: 127.1715 - val_viterbi_accuracy: 0.9801\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 3.6493 - viterbi_accuracy: 0.9793 - val_loss: 126.5611 - val_viterbi_accuracy: 0.9777\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 3.5720 - viterbi_accuracy: 0.9804 - val_loss: 126.6750 - val_viterbi_accuracy: 0.9795\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 3.4612 - viterbi_accuracy: 0.9808 - val_loss: 127.3440 - val_viterbi_accuracy: 0.9847\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 3.1762 - viterbi_accuracy: 0.9832 - val_loss: 127.1785 - val_viterbi_accuracy: 0.9800\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 3.1512 - viterbi_accuracy: 0.9825 - val_loss: 126.1358 - val_viterbi_accuracy: 0.9810\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 2.9115 - viterbi_accuracy: 0.9844 - val_loss: 126.2397 - val_viterbi_accuracy: 0.9812\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 2.9887 - viterbi_accuracy: 0.9822 - val_loss: 126.4270 - val_viterbi_accuracy: 0.9836\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 2.6951 - viterbi_accuracy: 0.9858 - val_loss: 125.8243 - val_viterbi_accuracy: 0.9789\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 2.5756 - viterbi_accuracy: 0.9868 - val_loss: 125.6917 - val_viterbi_accuracy: 0.9876\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 2.4445 - viterbi_accuracy: 0.9878 - val_loss: 126.8337 - val_viterbi_accuracy: 0.9886\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 2.4638 - viterbi_accuracy: 0.9868 - val_loss: 125.8652 - val_viterbi_accuracy: 0.9850\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 2.3966 - viterbi_accuracy: 0.9873 - val_loss: 126.4176 - val_viterbi_accuracy: 0.9867\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 2.1839 - viterbi_accuracy: 0.9891 - val_loss: 125.7147 - val_viterbi_accuracy: 0.9789\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 2.1950 - viterbi_accuracy: 0.9895 - val_loss: 125.6898 - val_viterbi_accuracy: 0.9890\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 2.0925 - viterbi_accuracy: 0.9893 - val_loss: 124.7758 - val_viterbi_accuracy: 0.9904\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 2.0505 - viterbi_accuracy: 0.9896 - val_loss: 126.3017 - val_viterbi_accuracy: 0.9851\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 2.0635 - viterbi_accuracy: 0.9894 - val_loss: 125.3623 - val_viterbi_accuracy: 0.9893\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 1.9180 - viterbi_accuracy: 0.9901 - val_loss: 125.7888 - val_viterbi_accuracy: 0.9847\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 1.7636 - viterbi_accuracy: 0.9915 - val_loss: 124.9663 - val_viterbi_accuracy: 0.9910\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 1.7088 - viterbi_accuracy: 0.9918 - val_loss: 125.6469 - val_viterbi_accuracy: 0.9915\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 1.7071 - viterbi_accuracy: 0.9920 - val_loss: 125.5597 - val_viterbi_accuracy: 0.9927\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 1.6432 - viterbi_accuracy: 0.9925 - val_loss: 125.4621 - val_viterbi_accuracy: 0.9889\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 1.4761 - viterbi_accuracy: 0.9937 - val_loss: 125.3638 - val_viterbi_accuracy: 0.9895\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 1.4768 - viterbi_accuracy: 0.9938 - val_loss: 125.5291 - val_viterbi_accuracy: 0.9922\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 1.4480 - viterbi_accuracy: 0.9932 - val_loss: 125.7334 - val_viterbi_accuracy: 0.9929\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 1.4291 - viterbi_accuracy: 0.9935 - val_loss: 125.0912 - val_viterbi_accuracy: 0.9932\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 1.3914 - viterbi_accuracy: 0.9941 - val_loss: 125.0914 - val_viterbi_accuracy: 0.9902\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 1.3614 - viterbi_accuracy: 0.9941 - val_loss: 125.3113 - val_viterbi_accuracy: 0.9959\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 1.4061 - viterbi_accuracy: 0.9931 - val_loss: 124.4352 - val_viterbi_accuracy: 0.9876\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 1.2151 - viterbi_accuracy: 0.9948 - val_loss: 125.3733 - val_viterbi_accuracy: 0.9867\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 1.3451 - viterbi_accuracy: 0.9937 - val_loss: 125.9986 - val_viterbi_accuracy: 0.9913\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 1.1458 - viterbi_accuracy: 0.9952 - val_loss: 125.2094 - val_viterbi_accuracy: 0.9964\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 1.1172 - viterbi_accuracy: 0.9951 - val_loss: 124.8817 - val_viterbi_accuracy: 0.9895\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 1.1532 - viterbi_accuracy: 0.9951 - val_loss: 124.7299 - val_viterbi_accuracy: 0.9944\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 1.1100 - viterbi_accuracy: 0.9947 - val_loss: 124.5146 - val_viterbi_accuracy: 0.9946\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 1.0567 - viterbi_accuracy: 0.9955 - val_loss: 125.3991 - val_viterbi_accuracy: 0.9943\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 1.1213 - viterbi_accuracy: 0.9948 - val_loss: 125.2172 - val_viterbi_accuracy: 0.9903\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 1.0739 - viterbi_accuracy: 0.9941 - val_loss: 125.2769 - val_viterbi_accuracy: 0.9870\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.9570 - viterbi_accuracy: 0.9956 - val_loss: 125.1286 - val_viterbi_accuracy: 0.9885\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 1.0371 - viterbi_accuracy: 0.9951 - val_loss: 124.7036 - val_viterbi_accuracy: 0.9899\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.9536 - viterbi_accuracy: 0.9956 - val_loss: 124.7810 - val_viterbi_accuracy: 0.9940\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.9268 - viterbi_accuracy: 0.9957 - val_loss: 125.0165 - val_viterbi_accuracy: 0.9878\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.9367 - viterbi_accuracy: 0.9960 - val_loss: 124.5572 - val_viterbi_accuracy: 0.9860\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 1.0350 - viterbi_accuracy: 0.9947 - val_loss: 125.0510 - val_viterbi_accuracy: 0.9878\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.9637 - viterbi_accuracy: 0.9960 - val_loss: 124.3177 - val_viterbi_accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, \n",
    "    histogram_freq=1,\n",
    "    profile_batch=\"1,20\"\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=100, \n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[callback, tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 40ms/step - loss: 124.3278 - viterbi_accuracy: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[124.32781982421875, 0.9909210205078125]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline Bi-LSTM CRF model has compiled, trained, and tested on the Re3d dataset successfully! Achieving 99.09% Accuracy on the test set, which is pretty good, as only ~68% of the tags are \"O\" tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1566ea1af4a47ca7acc671ba85a809484c1db5e7319af0d3caf0750117059574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
