{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Bi-LSTM CRF\"></a>\n",
    "\n",
    "# Bi-LSTM CRF Model\n",
    "\n",
    "We will leverage a Bi-LSTM CRF model as the baseline tagger.\n",
    "\n",
    "This notebook explores the construction of the tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path('notebooks/eda.ipynb').resolve().parents[2]\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "PREPARED_DIR = DATA_DIR / \"prepared\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>word</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>tags</th>\n",
       "      <th>single_tag</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[B-Temporal]</td>\n",
       "      <td>B-Temporal</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>week</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>[I-Temporal]</td>\n",
       "      <td>I-Temporal</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sees</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>start</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_num   word  start_idx  end_idx          tags  single_tag   POS\n",
       "0             0   This          0        4  [B-Temporal]  B-Temporal  PRON\n",
       "1             0   week          5        9  [I-Temporal]  I-Temporal  NOUN\n",
       "2             0   sees         10       14           [O]           O  VERB\n",
       "3             0    the         15       18           [O]           O  PRON\n",
       "4             0  start         19       24           [O]           O  VERB"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "df = pd.read_csv(PREPARED_DIR / \"master.csv\")\n",
    "df[\"tags\"] = df[\"tags\"].apply(literal_eval)\n",
    "df[\"single_tag\"] = df[\"tags\"].apply(lambda x: x[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4332 unique words\n"
     ]
    }
   ],
   "source": [
    "words = set(list(df['word'].values))\n",
    "words.add('PADword')\n",
    "n_words = len(words)\n",
    "print(f\"There are {n_words} unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 unique tags\n"
     ]
    }
   ],
   "source": [
    "tags = list(set(df[\"single_tag\"].values))\n",
    "n_tags = len(tags)\n",
    "print(f\"There are {n_tags} unique tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter:\n",
    "    \"\"\"Iterator to get a sentence sequence and its BIO tags\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, pos, t) for w, pos, t in zip(s[\"word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"single_tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence_num\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[self.n_sent]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1013 total sentence\n"
     ]
    }
   ],
   "source": [
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences\n",
    "print(f\"There are {len(sentences)} total sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make indices for ML modeling\n",
    "words2index = {w:i for i,w in enumerate(words)}\n",
    "tags2index = {t:i for i,t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 50\n",
    "y = [[tags2index[w[-1]] for w in s] for s in sentences]\n",
    "\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tags2index[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1013, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "X = [[words2index[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=words2index[\"PADword\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 15:32:56.016537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-15 15:32:56.036834: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "2022-11-15 15:32:56.036856: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: enyquist-X399-DESIGNARE-EX\n",
      "2022-11-15 15:32:56.036861: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: enyquist-X399-DESIGNARE-EX\n",
      "2022-11-15 15:32:56.036948: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.85.2\n",
      "2022-11-15 15:32:56.036966: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5\n",
      "2022-11-15 15:32:56.036971: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 520.61.5 does not match DSO version 510.85.2 -- cannot find working devices in this configuration\n",
      "2022-11-15 15:32:56.037646: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-11-15 15:32:56.043237: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3493015000 Hz\n",
      "2022-11-15 15:32:56.044279: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe080000b70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-15 15:32:56.044301: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_tensor = tf.convert_to_tensor(X)\n",
    "y_tensor = tf.convert_to_tensor(y)\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((x_tensor, y_tensor))\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(\n",
    "    ds, \n",
    "    ds_size, \n",
    "    train_split=0.8, \n",
    "    val_split=0.1, \n",
    "    test_split=0.1, \n",
    "    shuffle=True, \n",
    "    shuffle_size=1000\n",
    "):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=42)\n",
    "\n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds.batch(BATCH_SIZE), val_ds.batch(BATCH_SIZE), test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(\n",
    "    ds=ds,\n",
    "    ds_size=X.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential, Model\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Embedding, Bidirectional, LSTM, Dense, TimeDistributed, Input, Dropout\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow_addons.text import crf_log_likelihood, crf_decode\n",
    "\n",
    "\"\"\"\n",
    "Credit:\n",
    "https://github.com/ngoquanghuy99/POS-Tagging-BiLSTM-CRF\n",
    "\"\"\"\n",
    "\n",
    "class CRF(L.Layer):\n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 sparse_target=True,\n",
    "                 **kwargs):\n",
    "        \"\"\"    \n",
    "        Args:\n",
    "            output_dim (int): the number of labels to tag each temporal input.\n",
    "            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n",
    "        Input shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        Output shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        \"\"\"\n",
    "        super(CRF, self).__init__(**kwargs)\n",
    "        self.output_dim = int(output_dim) \n",
    "        self.sparse_target = sparse_target\n",
    "        self.input_spec = L.InputSpec(min_ndim=3)\n",
    "        self.supports_masking = False\n",
    "        self.sequence_lengths = None\n",
    "        self.transitions = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        f_shape = tf.TensorShape(input_shape)\n",
    "        input_spec = L.InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n",
    "\n",
    "        if f_shape[-1] is None:\n",
    "            raise ValueError('The last dimension of the inputs to `CRF` '\n",
    "                             'should be defined. Found `None`.')\n",
    "        if f_shape[-1] != self.output_dim:\n",
    "            raise ValueError('The last dimension of the input shape must be equal to output'\n",
    "                             ' shape. Use a linear layer if needed.')\n",
    "        self.input_spec = input_spec\n",
    "        self.transitions = self.add_weight(name='transitions',\n",
    "                                           shape=[self.output_dim, self.output_dim],\n",
    "                                           initializer='glorot_uniform',\n",
    "                                           trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Just pass the received mask from previous layer, to the next layer or\n",
    "        # manipulate it if this layer changes the shape of the input\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n",
    "        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n",
    "        if sequence_lengths is not None:\n",
    "            assert len(sequence_lengths.shape) == 2\n",
    "            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n",
    "            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n",
    "            assert seq_len_shape[1] == 1\n",
    "            self.sequence_lengths = K.flatten(sequence_lengths)\n",
    "        else:\n",
    "            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n",
    "                tf.shape(inputs)[1]\n",
    "            )\n",
    "\n",
    "        viterbi_sequence, _ = crf_decode(sequences,\n",
    "                                         self.transitions,\n",
    "                                         self.sequence_lengths)\n",
    "        output = K.one_hot(viterbi_sequence, self.output_dim)\n",
    "        return K.in_train_phase(sequences, output)\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        def crf_loss(y_true, y_pred):\n",
    "            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
    "            log_likelihood, self.transitions = crf_log_likelihood(\n",
    "                y_pred,\n",
    "                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
    "                self.sequence_lengths,\n",
    "                transition_params=self.transitions,\n",
    "            )\n",
    "            return tf.reduce_mean(-log_likelihood)\n",
    "        return crf_loss\n",
    "\n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        def viterbi_accuracy(y_true, y_pred):\n",
    "            # -1e10 to avoid zero at sum(mask)\n",
    "            mask = K.cast(\n",
    "                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
    "            shape = tf.shape(y_pred)\n",
    "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "            if self.sparse_target:\n",
    "                y_true = K.argmax(y_true, 2)\n",
    "            y_pred = K.cast(y_pred, 'int32')\n",
    "            y_true = K.cast(y_true, 'int32')\n",
    "            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
    "            return K.sum(corrects * mask) / K.sum(mask)\n",
    "        return viterbi_accuracy\n",
    "\n",
    "    @property\n",
    "    def f1(self):\n",
    "        def crf_f1(y_true, y_pred):\n",
    "            shape = tf.shape(y_pred)\n",
    "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "            true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "            possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "            predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "            precision = true_positives / (predicted_positives + K.epsilon())\n",
    "            recall = true_positives / (possible_positives + K.epsilon())\n",
    "            f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "            return f1_val\n",
    "        return crf_f1\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        tf.TensorShape(input_shape).assert_has_rank(3)\n",
    "        return input_shape[:2] + (self.output_dim,)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'sparse_target': self.sparse_target,\n",
    "            'supports_masking': self.supports_masking,\n",
    "            'transitions': K.eval(self.transitions)\n",
    "        }\n",
    "        base_config = super(CRF, self).get_config()\n",
    "        return dict(base_config, **config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIR = DATA_DIR / \"embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libaries\n",
    "import io\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "# third party libraries\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "\n",
    "\n",
    "def create_model(\n",
    "    vocab_size: int, max_length: int, embedding_dim: int, word_index: Dict[str, int], tag_index: Dict[str, int]\n",
    ") -> Tuple[models.Model]:\n",
    "    \"\"\"Create Bi-LSTM CRF model in tensorflow.\n",
    "\n",
    "    Model1 is the trainable model. Model2 is for predictions and returns:\n",
    "    [predicted labels, LSTM hidden state (Forward and backward), LSTM cell state (forward and backward), embeddings]\n",
    "\n",
    "    This is leveraged to build the REINFORCE states.\n",
    "\n",
    "    Adapted from:\n",
    "    https://github.com/ngoquanghuy99/POS-Tagging-BiLSTM-CRF\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of vocabulary\n",
    "        max_length (int): Max sequence length\n",
    "        embedding_dim (int): Size of embedding. Make sure to match size of GloVe embedding.\n",
    "        word_index (Dict[str, int]): Index mapping words to ints\n",
    "        tag_index (Dict[str, int]): Index mapping tokens to ints\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Model]: Compiled Model and Non-compiled Model\n",
    "        with exposed LSTM and embedding layers\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings_index = {}\n",
    "    with io.open(EMBEDDING_DIR / \"glove.6B.100d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            curr_word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype=\"float64\")\n",
    "            embeddings_index[curr_word] = coefs\n",
    "        embeddings_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "        for word, i in word_index.items():\n",
    "            if i > vocab_size:\n",
    "                continue\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embeddings_matrix[i] = embedding_vector\n",
    "\n",
    "    inputs = layers.Input(shape=(max_length, ))\n",
    "\n",
    "    embeddings = layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=max_length,\n",
    "        weights=[embeddings_matrix],\n",
    "        mask_zero=True\n",
    "    )(inputs)\n",
    "\n",
    "    lstm_out, sh_fw, sc_fw, sh_bw, sc_bw = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            units=embedding_dim, return_sequences=True, return_state=True, recurrent_dropout=0.01\n",
    "        )\n",
    "    )(embeddings)\n",
    "\n",
    "    time_dist = layers.TimeDistributed(layers.Dense(len(tag_index)))(lstm_out)\n",
    "    \n",
    "    crf = CRF(len(tag_index), sparse_target=False)\n",
    "    pred = crf(time_dist)\n",
    "\n",
    "    model1 = models.Model(inputs=[inputs], outputs=[pred])\n",
    "    model2 = models.Model(inputs=[inputs], outputs=[pred, sh_fw, sc_fw, sh_bw, sc_bw, embeddings])\n",
    "\n",
    "    model1.compile(optimizer=\"adam\", loss=crf.loss, metrics=[crf.accuracy])\n",
    "    model1.summary()\n",
    "\n",
    "    return model1, model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "log_dir = ROOT_DIR / \"models/logs/\"\n",
    "\n",
    "if any(log_dir.iterdir()):\n",
    "    for i in log_dir.glob(\"**/*\"):\n",
    "        if i.is_dir():\n",
    "            shutil.rmtree(i)\n",
    "        else:\n",
    "            i.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 100)           433200    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional [(None, 50, 200), (None,  160800    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 50, 29)            5829      \n",
      "_________________________________________________________________\n",
      "crf (CRF)                    (None, 50, 29)            841       \n",
      "=================================================================\n",
      "Total params: 600,670\n",
      "Trainable params: 600,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1, model2 = create_model(\n",
    "    vocab_size=len(words2index),\n",
    "    max_length=50,\n",
    "    embedding_dim=100,\n",
    "    word_index=words2index,\n",
    "    tag_index=tags2index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 15:33:12.847610: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      "2022-11-15 15:33:12.925520: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 114.6862 - viterbi_accuracy: 0.6133 - val_loss: 128.0542 - val_viterbi_accuracy: 0.8278\n",
      "Epoch 2/100\n",
      " 6/13 [============>.................] - ETA: 0s - loss: 51.8897 - viterbi_accuracy: 0.8465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 15:33:24.019861: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_15_15_33_22\n",
      "2022-11-15 15:33:26.394796: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_15_15_33_22/enyquist-X399-DESIGNARE-EX.trace.json.gz\n",
      "2022-11-15 15:33:27.533344: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 136.557 ms\n",
      "\n",
      "2022-11-15 15:33:27.551659: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_15_15_33_22Dumped tool data for overview_page.pb to /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_15_15_33_22/enyquist-X399-DESIGNARE-EX.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_15_15_33_22/enyquist-X399-DESIGNARE-EX.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_15_15_33_22/enyquist-X399-DESIGNARE-EX.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_15_15_33_22/enyquist-X399-DESIGNARE-EX.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 9s 673ms/step - loss: 47.5260 - viterbi_accuracy: 0.8459 - val_loss: 126.5423 - val_viterbi_accuracy: 0.8430\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 39.9703 - viterbi_accuracy: 0.8445 - val_loss: 125.8219 - val_viterbi_accuracy: 0.8486\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 35.2214 - viterbi_accuracy: 0.8486 - val_loss: 126.0976 - val_viterbi_accuracy: 0.8470\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 32.7713 - viterbi_accuracy: 0.8466 - val_loss: 126.1025 - val_viterbi_accuracy: 0.8347\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 29.4232 - viterbi_accuracy: 0.8497 - val_loss: 125.8015 - val_viterbi_accuracy: 0.8417\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 27.7148 - viterbi_accuracy: 0.8495 - val_loss: 124.2184 - val_viterbi_accuracy: 0.8690\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 24.9168 - viterbi_accuracy: 0.8608 - val_loss: 124.0234 - val_viterbi_accuracy: 0.8691\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 23.3225 - viterbi_accuracy: 0.8673 - val_loss: 123.8136 - val_viterbi_accuracy: 0.8691\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 20.9716 - viterbi_accuracy: 0.8803 - val_loss: 122.6153 - val_viterbi_accuracy: 0.8896\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 18.9601 - viterbi_accuracy: 0.8918 - val_loss: 122.6580 - val_viterbi_accuracy: 0.8843\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 18.2337 - viterbi_accuracy: 0.8957 - val_loss: 121.9788 - val_viterbi_accuracy: 0.8924\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 16.0856 - viterbi_accuracy: 0.9060 - val_loss: 120.0938 - val_viterbi_accuracy: 0.9246\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 15.4873 - viterbi_accuracy: 0.9117 - val_loss: 120.2601 - val_viterbi_accuracy: 0.9219\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 13.8597 - viterbi_accuracy: 0.9226 - val_loss: 120.1962 - val_viterbi_accuracy: 0.9248\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 12.9237 - viterbi_accuracy: 0.9269 - val_loss: 119.8458 - val_viterbi_accuracy: 0.9244\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 12.0828 - viterbi_accuracy: 0.9312 - val_loss: 119.9370 - val_viterbi_accuracy: 0.9212\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 11.4101 - viterbi_accuracy: 0.9351 - val_loss: 118.7590 - val_viterbi_accuracy: 0.9420\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 10.5575 - viterbi_accuracy: 0.9389 - val_loss: 118.3434 - val_viterbi_accuracy: 0.9494\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 10.1167 - viterbi_accuracy: 0.9420 - val_loss: 118.3414 - val_viterbi_accuracy: 0.9475\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 9.6788 - viterbi_accuracy: 0.9434 - val_loss: 117.7281 - val_viterbi_accuracy: 0.9578\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 8.7746 - viterbi_accuracy: 0.9485 - val_loss: 117.8258 - val_viterbi_accuracy: 0.9516\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 8.2433 - viterbi_accuracy: 0.9507 - val_loss: 117.8197 - val_viterbi_accuracy: 0.9485\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 8.2579 - viterbi_accuracy: 0.9493 - val_loss: 117.2991 - val_viterbi_accuracy: 0.9598\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 7.2849 - viterbi_accuracy: 0.9569 - val_loss: 117.5361 - val_viterbi_accuracy: 0.9500\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 6.9368 - viterbi_accuracy: 0.9578 - val_loss: 117.1725 - val_viterbi_accuracy: 0.9562\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 6.5947 - viterbi_accuracy: 0.9611 - val_loss: 116.7700 - val_viterbi_accuracy: 0.9608\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 6.1527 - viterbi_accuracy: 0.9632 - val_loss: 116.5427 - val_viterbi_accuracy: 0.9640\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 6.3345 - viterbi_accuracy: 0.9619 - val_loss: 116.2440 - val_viterbi_accuracy: 0.9683\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 5.5574 - viterbi_accuracy: 0.9676 - val_loss: 116.2769 - val_viterbi_accuracy: 0.9643\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 5.0957 - viterbi_accuracy: 0.9703 - val_loss: 116.1553 - val_viterbi_accuracy: 0.9712\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 5.0077 - viterbi_accuracy: 0.9709 - val_loss: 115.8232 - val_viterbi_accuracy: 0.9739\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 4.6434 - viterbi_accuracy: 0.9731 - val_loss: 115.4706 - val_viterbi_accuracy: 0.9790\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 4.5371 - viterbi_accuracy: 0.9741 - val_loss: 115.5299 - val_viterbi_accuracy: 0.9725\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 4.2854 - viterbi_accuracy: 0.9757 - val_loss: 115.1723 - val_viterbi_accuracy: 0.9791\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 3.9277 - viterbi_accuracy: 0.9785 - val_loss: 115.2594 - val_viterbi_accuracy: 0.9780\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 3.8802 - viterbi_accuracy: 0.9786 - val_loss: 115.0130 - val_viterbi_accuracy: 0.9817\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 3.6096 - viterbi_accuracy: 0.9801 - val_loss: 114.6418 - val_viterbi_accuracy: 0.9833\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 3.3695 - viterbi_accuracy: 0.9817 - val_loss: 114.7402 - val_viterbi_accuracy: 0.9786\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 3.3025 - viterbi_accuracy: 0.9831 - val_loss: 114.9165 - val_viterbi_accuracy: 0.9795\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 3.1400 - viterbi_accuracy: 0.9831 - val_loss: 114.7079 - val_viterbi_accuracy: 0.9849\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 3.0178 - viterbi_accuracy: 0.9835 - val_loss: 114.6323 - val_viterbi_accuracy: 0.9805\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 2.9750 - viterbi_accuracy: 0.9840 - val_loss: 114.2850 - val_viterbi_accuracy: 0.9823\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 2.7112 - viterbi_accuracy: 0.9852 - val_loss: 114.2380 - val_viterbi_accuracy: 0.9841\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 2.7022 - viterbi_accuracy: 0.9843 - val_loss: 114.3232 - val_viterbi_accuracy: 0.9858\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 2.4547 - viterbi_accuracy: 0.9876 - val_loss: 114.1021 - val_viterbi_accuracy: 0.9813\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 2.4169 - viterbi_accuracy: 0.9873 - val_loss: 113.7842 - val_viterbi_accuracy: 0.9908\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 2.2614 - viterbi_accuracy: 0.9890 - val_loss: 113.9673 - val_viterbi_accuracy: 0.9921\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 2.1933 - viterbi_accuracy: 0.9887 - val_loss: 114.0345 - val_viterbi_accuracy: 0.9859\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 2.1647 - viterbi_accuracy: 0.9896 - val_loss: 114.0398 - val_viterbi_accuracy: 0.9874\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 2.0007 - viterbi_accuracy: 0.9900 - val_loss: 113.8655 - val_viterbi_accuracy: 0.9832\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 2.0351 - viterbi_accuracy: 0.9894 - val_loss: 113.6355 - val_viterbi_accuracy: 0.9885\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 1.9495 - viterbi_accuracy: 0.9900 - val_loss: 113.2922 - val_viterbi_accuracy: 0.9900\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 1.8719 - viterbi_accuracy: 0.9908 - val_loss: 113.9743 - val_viterbi_accuracy: 0.9853\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 1.8793 - viterbi_accuracy: 0.9897 - val_loss: 113.4273 - val_viterbi_accuracy: 0.9912\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 1.7441 - viterbi_accuracy: 0.9911 - val_loss: 113.4666 - val_viterbi_accuracy: 0.9904\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 1.6955 - viterbi_accuracy: 0.9913 - val_loss: 112.9994 - val_viterbi_accuracy: 0.9946\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 1.5776 - viterbi_accuracy: 0.9921 - val_loss: 113.4310 - val_viterbi_accuracy: 0.9927\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 1.5379 - viterbi_accuracy: 0.9930 - val_loss: 113.1939 - val_viterbi_accuracy: 0.9944\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 1.4964 - viterbi_accuracy: 0.9934 - val_loss: 113.4358 - val_viterbi_accuracy: 0.9869\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 1.4270 - viterbi_accuracy: 0.9941 - val_loss: 113.4697 - val_viterbi_accuracy: 0.9910\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 1.3778 - viterbi_accuracy: 0.9935 - val_loss: 113.2694 - val_viterbi_accuracy: 0.9918\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 1.4148 - viterbi_accuracy: 0.9928 - val_loss: 113.0652 - val_viterbi_accuracy: 0.9937\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 1.4542 - viterbi_accuracy: 0.9927 - val_loss: 112.9752 - val_viterbi_accuracy: 0.9937\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 1.3825 - viterbi_accuracy: 0.9933 - val_loss: 113.0714 - val_viterbi_accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, \n",
    "    histogram_freq=1,\n",
    "    profile_batch=\"1,20\"\n",
    ")\n",
    "\n",
    "\n",
    "history = model1.fit(\n",
    "    train_ds,\n",
    "    epochs=100, \n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[callback, tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline Bi-LSTM CRF model has compiled, trained, and tested on the Re3d dataset successfully! Achieving ~99.00% Accuracy on the test set, which is pretty good, as only ~68% of the tags are \"O\" tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 20ms/step - loss: 112.8591 - viterbi_accuracy: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[112.85912322998047, 0.9923354983329773]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_model` creates two models, one which is trainable and one which is used for prediction. This model outputs:\n",
    "* predictions\n",
    "* LSTM hidden state forward pass\n",
    "* LSTM cell state forward pass\n",
    "* LSTM hidden state backward pass\n",
    "* LSTM cell state backward pass\n",
    "* Embeddings\n",
    "\n",
    "This is leveraged in construction of the REINFORCE states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model2.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9456301 , -0.20230967,  0.89551836,  0.30929264,  0.9070361 ,\n",
       "       -0.7689723 ,  0.96961737, -0.7181937 , -0.96594965, -0.9800316 ,\n",
       "        0.9646359 ,  0.09062003, -0.06115296, -0.46046507, -0.88109106,\n",
       "        0.96693075, -0.88716763,  0.3860504 ,  0.5656328 , -0.99562603,\n",
       "        0.83960235,  0.4403895 ,  0.997928  ,  0.9886104 , -0.91121924,\n",
       "        0.19685347,  0.7100637 ,  0.8827886 ,  0.9306269 ,  0.95987576,\n",
       "       -0.977393  , -0.895448  ,  0.89138913, -0.05796352,  0.7777271 ,\n",
       "       -0.9391198 ,  0.26223004, -0.6093647 , -0.8600042 , -0.25359493,\n",
       "        0.8589747 , -0.37789324,  0.9419344 , -0.82511884, -0.6723171 ,\n",
       "        0.8910508 ,  0.862001  ,  0.9543241 ,  0.16341835,  0.48524523,\n",
       "        0.8390463 ,  0.8130374 , -0.5667882 , -0.61088943,  0.91868997,\n",
       "       -0.98205394,  0.9771145 , -0.9939071 , -0.9327623 , -0.9619404 ,\n",
       "       -0.976128  , -0.29773775, -0.95627487,  0.09384784, -0.9693913 ,\n",
       "        0.87953794,  0.83039594,  0.9909103 ,  0.9233074 ,  0.42210376,\n",
       "        0.7459206 ,  0.9766206 , -0.8686683 , -0.8454086 ,  0.94729155,\n",
       "        0.96998775,  0.6232947 ,  0.9832136 ,  0.9787903 , -0.81463456,\n",
       "        0.00257874,  0.9933045 ,  0.9746658 , -0.6219911 , -0.72269535,\n",
       "       -0.38305232,  0.42257735,  0.94126517, -0.6874613 , -0.7042208 ,\n",
       "       -0.02511709, -0.88850343, -0.95149577, -0.8620033 , -0.9631538 ,\n",
       "        0.9655462 , -0.69540024,  0.91615796,  0.9245238 , -0.7181146 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The LSTM hidden state forward pass of the first test sequence\n",
    "preds[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model2.predict(tf.convert_to_tensor(X[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3033, 1946, 2120, 2021,  571, 3006, 4284, 3935,  542, 3006,    8,\n",
       "        844, 2021, 2674, 3006, 2021,  350, 3587, 2313,  185, 3457, 3791,\n",
       "       2021, 3878, 3006, 4065, 2709, 1635,  930,  921, 1069, 1025, 2149,\n",
       "       4135, 2111,   24, 2944,  604,  522, 4011, 2021, 1825, 4141, 2634,\n",
       "       1316, 1316, 1316, 1316, 1316, 1316], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = {idx: word for word, idx in words2index.items()}\n",
    "index2tag = {idx: tag for tag, idx in tags2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: This \tTag: B-Temporal\n",
      "Word: week \tTag: I-Temporal\n",
      "Word: sees \tTag: O\n",
      "Word: the \tTag: O\n",
      "Word: start \tTag: O\n",
      "Word: of \tTag: O\n",
      "Word: a \tTag: O\n",
      "Word: second \tTag: O\n",
      "Word: round \tTag: O\n",
      "Word: of \tTag: O\n",
      "Word: talks \tTag: O\n",
      "Word: in \tTag: O\n",
      "Word: the \tTag: O\n",
      "Word: framework \tTag: O\n",
      "Word: of \tTag: O\n",
      "Word: the \tTag: O\n",
      "Word: European \tTag: B-Organisation\n",
      "Word: Union \tTag: I-Organisation\n",
      "Word: 's \tTag: O\n",
      "Word: Regional \tTag: O\n",
      "Word: Initiative \tTag: O\n",
      "Word: on \tTag: O\n",
      "Word: the \tTag: O\n",
      "Word: future \tTag: O\n",
      "Word: of \tTag: O\n",
      "Word: Syria \tTag: B-Location\n",
      "Word: , \tTag: O\n",
      "Word: High \tTag: B-Person\n",
      "Word: Representative \tTag: I-Person\n",
      "Word: Federica \tTag: I-Person\n",
      "Word: Mogherini \tTag: I-Person\n",
      "Word: ’s \tTag: I-Person\n",
      "Word: initiative \tTag: O\n",
      "Word: to \tTag: O\n",
      "Word: identify \tTag: O\n",
      "Word: post \tTag: O\n",
      "Word: - \tTag: O\n",
      "Word: conflict \tTag: O\n",
      "Word: arrangements \tTag: O\n",
      "Word: for \tTag: O\n",
      "Word: the \tTag: B-Location\n",
      "Word: country \tTag: I-Location\n",
      "Word: . \tTag: O\n",
      "Word: \n",
      " \tTag: O\n",
      "Word: PADword \tTag: O\n",
      "Word: PADword \tTag: O\n",
      "Word: PADword \tTag: O\n",
      "Word: PADword \tTag: O\n",
      "Word: PADword \tTag: O\n",
      "Word: PADword \tTag: O\n"
     ]
    }
   ],
   "source": [
    "for pred, word_idx in zip(pred[0][0], X[0]):\n",
    "    word = index2word[word_idx]\n",
    "    tag_idx = np.argmax(pred)\n",
    "    tag = index2tag[tag_idx]\n",
    "    print(f\"Word: {word} \\tTag: {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'PRON', 'B-Temporal'),\n",
       " ('week', 'NOUN', 'I-Temporal'),\n",
       " ('sees', 'VERB', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('start', 'VERB', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('a', 'PRON', 'O'),\n",
       " ('second', 'ADJ', 'O'),\n",
       " ('round', 'ADJ', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('talks', 'NOUN', 'O'),\n",
       " ('in', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('framework', 'NOUN', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('European', 'ADJ', 'B-Organisation'),\n",
       " ('Union', 'NOUN', 'I-Organisation'),\n",
       " (\"'s\", 'AUX', 'O'),\n",
       " ('Regional', 'ADJ', 'O'),\n",
       " ('Initiative', 'NOUN', 'O'),\n",
       " ('on', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('future', 'NOUN', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('Syria', 'PROPN', 'B-Location'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('High', 'ADJ', 'B-Person'),\n",
       " ('Representative', 'ADJ', 'I-Person'),\n",
       " ('Federica', 'PROPN', 'I-Person'),\n",
       " ('Mogherini', 'PROPN', 'I-Person'),\n",
       " ('’s', 'VERB', 'I-Person'),\n",
       " ('initiative', 'NOUN', 'O'),\n",
       " ('to', 'PART', 'O'),\n",
       " ('identify', 'VERB', 'O'),\n",
       " ('post', 'ADV', 'O'),\n",
       " ('-', 'PUNCT', 'O'),\n",
       " ('conflict', 'NOUN', 'O'),\n",
       " ('arrangements', 'NOUN', 'O'),\n",
       " ('for', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'B-Location'),\n",
       " ('country', 'NOUN', 'I-Location'),\n",
       " ('.', 'PUNCT', 'O'),\n",
       " ('\\n', 'SPACE', 'O')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1566ea1af4a47ca7acc671ba85a809484c1db5e7319af0d3caf0750117059574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
