{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Bi-LSTM CRF\"></a>\n",
    "\n",
    "# Bi-LSTM CRF Model\n",
    "\n",
    "We will leverage a Bi-LSTM CRF model as the baseline tagger.\n",
    "\n",
    "This notebook explores the construction of the tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path('notebooks/eda.ipynb').resolve().parents[2]\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "PREPARED_DIR = DATA_DIR / \"prepared\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>word</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>tags</th>\n",
       "      <th>single_tag</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[B-Temporal]</td>\n",
       "      <td>B-Temporal</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>week</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>[I-Temporal]</td>\n",
       "      <td>I-Temporal</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sees</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>start</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>[O]</td>\n",
       "      <td>O</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_num   word  start_idx  end_idx          tags  single_tag   POS\n",
       "0             0   This          0        4  [B-Temporal]  B-Temporal  PRON\n",
       "1             0   week          5        9  [I-Temporal]  I-Temporal  NOUN\n",
       "2             0   sees         10       14           [O]           O  VERB\n",
       "3             0    the         15       18           [O]           O  PRON\n",
       "4             0  start         19       24           [O]           O  VERB"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "df = pd.read_csv(PREPARED_DIR / \"master.csv\")\n",
    "df[\"tags\"] = df[\"tags\"].apply(literal_eval)\n",
    "df[\"single_tag\"] = df[\"tags\"].apply(lambda x: x[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4317 unique words\n"
     ]
    }
   ],
   "source": [
    "words = set(list(df['word'].values))\n",
    "words.add('PADword')\n",
    "n_words = len(words)\n",
    "print(f\"There are {n_words} unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m([item[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m sublist \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sublist])\n\u001b[1;32m      2\u001b[0m words\u001b[39m.\u001b[39madd(\u001b[39m\"\u001b[39m\u001b[39mPADword\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(words))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "words = set([item[0] for sublist in sentences for item in sublist])\n",
    "words.add(\"PADword\")\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'PRON', 'B-Temporal'),\n",
       " ('week', 'NOUN', 'I-Temporal'),\n",
       " ('sees', 'VERB', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('start', 'VERB', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('a', 'PRON', 'O'),\n",
       " ('second', 'ADJ', 'O'),\n",
       " ('round', 'ADJ', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('talks', 'NOUN', 'O'),\n",
       " ('in', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('framework', 'NOUN', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('European', 'ADJ', 'B-Organisation'),\n",
       " ('Union', 'NOUN', 'I-Organisation'),\n",
       " (\"'s\", 'AUX', 'O'),\n",
       " ('Regional', 'ADJ', 'O'),\n",
       " ('Initiative', 'NOUN', 'O'),\n",
       " ('on', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('future', 'NOUN', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('Syria', 'PROPN', 'B-Location'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('High', 'ADJ', 'B-Person'),\n",
       " ('Representative', 'ADJ', 'I-Person'),\n",
       " ('Federica', 'PROPN', 'I-Person'),\n",
       " ('Mogherini', 'PROPN', 'I-Person'),\n",
       " ('â€™s', 'VERB', 'I-Person'),\n",
       " ('initiative', 'NOUN', 'O'),\n",
       " ('to', 'PART', 'O'),\n",
       " ('identify', 'VERB', 'O'),\n",
       " ('post', 'ADV', 'O'),\n",
       " ('-', 'PUNCT', 'O'),\n",
       " ('conflict', 'NOUN', 'O'),\n",
       " ('arrangements', 'NOUN', 'O'),\n",
       " ('for', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'B-Location'),\n",
       " ('country', 'NOUN', 'I-Location'),\n",
       " ('.', 'PUNCT', 'O')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 unique tags\n"
     ]
    }
   ],
   "source": [
    "tags = list(set(df[\"single_tag\"].values))\n",
    "n_tags = len(tags)\n",
    "print(f\"There are {n_tags} unique tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "tags = set([item[-1] for sublist in sentences for item in sublist])\n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 14:14:09.142683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-21 14:14:09.142830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 14:14:09.142966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 3080 Ti computeCapability: 8.6\n",
      "coreClock: 1.665GHz coreCount: 80 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 849.46GiB/s\n",
      "2022-11-21 14:14:09.143078: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2022-11-21 14:14:09.143135: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-21 14:14:09.145650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-21 14:14:09.145958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-21 14:14:09.146013: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-21 14:14:09.146053: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-21 14:14:09.146094: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-21 14:14:09.146100: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from rlner.utils import SentenceGetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 928 total sentences\n"
     ]
    }
   ],
   "source": [
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences\n",
    "print(f\"There are {len(sentences)} total sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make indices for ML modeling\n",
    "words2index = {w:i for i,w in enumerate(words)}\n",
    "tags2index = {t:i for i,t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 50\n",
    "y = [[tags2index[w[-1]] for w in s] for s in sentences]\n",
    "\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tags2index[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "X = [[words2index[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=words2index[\"PADword\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 14:14:19.100560: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-11-21 14:14:19.131895: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3492885000 Hz\n",
      "2022-11-21 14:14:19.133271: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7cb0000b70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-21 14:14:19.133303: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-11-21 14:14:19.134962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-21 14:14:19.134977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_tensor = tf.convert_to_tensor(X)\n",
    "y_tensor = tf.convert_to_tensor(y)\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((x_tensor, y_tensor))\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(\n",
    "    ds, \n",
    "    ds_size, \n",
    "    train_split=0.8, \n",
    "    val_split=0.1, \n",
    "    test_split=0.1, \n",
    "    shuffle=True, \n",
    "    shuffle_size=1000\n",
    "):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=42)\n",
    "\n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds.batch(BATCH_SIZE), val_ds.batch(BATCH_SIZE), test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(\n",
    "    ds=ds,\n",
    "    ds_size=X.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow_addons.text import crf_log_likelihood, crf_decode\n",
    "\n",
    "\"\"\"\n",
    "Credit:\n",
    "https://github.com/ngoquanghuy99/POS-Tagging-BiLSTM-CRF\n",
    "\"\"\"\n",
    "\n",
    "class CRF(L.Layer):\n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 sparse_target=True,\n",
    "                 **kwargs):\n",
    "        \"\"\"    \n",
    "        Args:\n",
    "            output_dim (int): the number of labels to tag each temporal input.\n",
    "            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n",
    "        Input shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        Output shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        \"\"\"\n",
    "        super(CRF, self).__init__(**kwargs)\n",
    "        self.output_dim = int(output_dim) \n",
    "        self.sparse_target = sparse_target\n",
    "        self.input_spec = L.InputSpec(min_ndim=3)\n",
    "        self.supports_masking = False\n",
    "        self.sequence_lengths = None\n",
    "        self.transitions = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        f_shape = tf.TensorShape(input_shape)\n",
    "        input_spec = L.InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n",
    "\n",
    "        if f_shape[-1] is None:\n",
    "            raise ValueError('The last dimension of the inputs to `CRF` '\n",
    "                             'should be defined. Found `None`.')\n",
    "        if f_shape[-1] != self.output_dim:\n",
    "            raise ValueError('The last dimension of the input shape must be equal to output'\n",
    "                             ' shape. Use a linear layer if needed.')\n",
    "        self.input_spec = input_spec\n",
    "        self.transitions = self.add_weight(name='transitions',\n",
    "                                           shape=[self.output_dim, self.output_dim],\n",
    "                                           initializer='glorot_uniform',\n",
    "                                           trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Just pass the received mask from previous layer, to the next layer or\n",
    "        # manipulate it if this layer changes the shape of the input\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n",
    "        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n",
    "        if sequence_lengths is not None:\n",
    "            assert len(sequence_lengths.shape) == 2\n",
    "            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n",
    "            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n",
    "            assert seq_len_shape[1] == 1\n",
    "            self.sequence_lengths = K.flatten(sequence_lengths)\n",
    "        else:\n",
    "            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n",
    "                tf.shape(inputs)[1]\n",
    "            )\n",
    "\n",
    "        viterbi_sequence, _ = crf_decode(sequences,\n",
    "                                         self.transitions,\n",
    "                                         self.sequence_lengths)\n",
    "        output = K.one_hot(viterbi_sequence, self.output_dim)\n",
    "        return K.in_train_phase(sequences, output)\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        def crf_loss(y_true, y_pred):\n",
    "            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
    "            log_likelihood, self.transitions = crf_log_likelihood(\n",
    "                y_pred,\n",
    "                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
    "                self.sequence_lengths,\n",
    "                transition_params=self.transitions,\n",
    "            )\n",
    "            return tf.reduce_mean(-log_likelihood)\n",
    "        return crf_loss\n",
    "\n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        def viterbi_accuracy(y_true, y_pred):\n",
    "            # -1e10 to avoid zero at sum(mask)\n",
    "            mask = K.cast(\n",
    "                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
    "            shape = tf.shape(y_pred)\n",
    "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "            if self.sparse_target:\n",
    "                y_true = K.argmax(y_true, 2)\n",
    "            y_pred = K.cast(y_pred, 'int32')\n",
    "            y_true = K.cast(y_true, 'int32')\n",
    "            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
    "            return K.sum(corrects * mask) / K.sum(mask)\n",
    "        return viterbi_accuracy\n",
    "\n",
    "    @property\n",
    "    def f1(self):\n",
    "        def crf_f1(y_true, y_pred):\n",
    "            shape = tf.shape(y_pred)\n",
    "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "            true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "            possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "            predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "            precision = true_positives / (predicted_positives + K.epsilon())\n",
    "            recall = true_positives / (possible_positives + K.epsilon())\n",
    "            f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "            return f1_val\n",
    "        return crf_f1\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        tf.TensorShape(input_shape).assert_has_rank(3)\n",
    "        return input_shape[:2] + (self.output_dim,)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'sparse_target': self.sparse_target,\n",
    "            'supports_masking': self.supports_masking,\n",
    "            'transitions': K.eval(self.transitions)\n",
    "        }\n",
    "        base_config = super(CRF, self).get_config()\n",
    "        return dict(base_config, **config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIR = DATA_DIR / \"embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libaries\n",
    "import io\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "# third party libraries\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "\n",
    "\n",
    "def create_model(\n",
    "    vocab_size: int, max_length: int, embedding_dim: int, word_index: Dict[str, int], tag_index: Dict[str, int]\n",
    ") -> Tuple[models.Model]:\n",
    "    \"\"\"Create Bi-LSTM CRF model in tensorflow.\n",
    "\n",
    "    Model1 is the trainable model. Model2 is for predictions and returns:\n",
    "    [predicted labels, LSTM hidden state (Forward and backward), LSTM cell state (forward and backward), embeddings]\n",
    "\n",
    "    This is leveraged to build the REINFORCE states.\n",
    "\n",
    "    Adapted from:\n",
    "    https://github.com/ngoquanghuy99/POS-Tagging-BiLSTM-CRF\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of vocabulary\n",
    "        max_length (int): Max sequence length\n",
    "        embedding_dim (int): Size of embedding. Make sure to match size of GloVe embedding.\n",
    "        word_index (Dict[str, int]): Index mapping words to ints\n",
    "        tag_index (Dict[str, int]): Index mapping tokens to ints\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Model]: Compiled Model and Non-compiled Model\n",
    "        with exposed LSTM and embedding layers\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings_index = {}\n",
    "    with io.open(EMBEDDING_DIR / \"glove.6B.100d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            curr_word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype=\"float64\")\n",
    "            embeddings_index[curr_word] = coefs\n",
    "        embeddings_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "        for word, i in word_index.items():\n",
    "            if i > vocab_size:\n",
    "                continue\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embeddings_matrix[i] = embedding_vector\n",
    "\n",
    "    inputs = layers.Input(shape=(max_length, ))\n",
    "\n",
    "    embeddings = layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=max_length,\n",
    "        weights=[embeddings_matrix],\n",
    "        mask_zero=True\n",
    "    )(inputs)\n",
    "\n",
    "    lstm_out, sh_fw, sc_fw, sh_bw, sc_bw = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            units=embedding_dim, return_sequences=True, return_state=True, recurrent_dropout=0.01\n",
    "        )\n",
    "    )(embeddings)\n",
    "\n",
    "    time_dist = layers.TimeDistributed(layers.Dense(len(tag_index)))(lstm_out)\n",
    "    \n",
    "    crf = CRF(len(tag_index), sparse_target=False)\n",
    "    pred = crf(time_dist)\n",
    "\n",
    "    model1 = models.Model(inputs=[inputs], outputs=[pred])\n",
    "    model2 = models.Model(inputs=[inputs], outputs=[pred, lstm_out, sh_fw, sc_fw, sh_bw, sc_bw, embeddings])\n",
    "\n",
    "    model1.compile(optimizer=\"adam\", loss=crf.loss, metrics=[crf.accuracy])\n",
    "    model1.summary()\n",
    "\n",
    "    return model1, model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "log_dir = ROOT_DIR / \"models/logs/\"\n",
    "\n",
    "if any(log_dir.iterdir()):\n",
    "    for i in log_dir.glob(\"**/*\"):\n",
    "        if i.is_dir():\n",
    "            shutil.rmtree(i)\n",
    "        else:\n",
    "            i.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 100)           431700    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection [(None, 50, 200), (None,  160800    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 29)            5829      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 50, 29)            841       \n",
      "=================================================================\n",
      "Total params: 599,170\n",
      "Trainable params: 599,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1, model2 = create_model(\n",
    "    vocab_size=len(words2index),\n",
    "    max_length=50,\n",
    "    embedding_dim=100,\n",
    "    word_index=words2index,\n",
    "    tag_index=tags2index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 14:23:06.694081: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      "2022-11-21 14:23:06.694138: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1408] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-11-21 14:23:06.694150: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1447] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-11-21 14:23:06.694168: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1430] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-11-21 14:23:06.822630: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      "2022-11-21 14:23:06.822669: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1408] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-11-21 14:23:06.822677: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1447] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 122.7659 - viterbi_accuracy: 0.5854 - val_loss: 139.7185 - val_viterbi_accuracy: 0.4431\n",
      "Epoch 2/100\n",
      " 7/12 [================>.............] - ETA: 0s - loss: 53.1746 - viterbi_accuracy: 0.8376"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 14:23:15.140346: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1430] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-11-21 14:23:15.600928: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:216]  GpuTracer has collected 0 callback api events and 0 activity events.\n",
      "2022-11-21 14:23:18.120181: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_21_14_23_16\n",
      "2022-11-21 14:23:20.652994: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_21_14_23_16/enyquist-X399-DESIGNARE-EX.trace.json.gz\n",
      "2022-11-21 14:23:21.331460: E tensorflow/core/profiler/utils/hardware_type_utils.cc:60] Invalid GPU compute capability.\n",
      "2022-11-21 14:23:21.553311: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0 ms\n",
      "\n",
      "2022-11-21 14:23:21.559383: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_21_14_23_16Dumped tool data for overview_page.pb to /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_21_14_23_16/enyquist-X399-DESIGNARE-EX.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_21_14_23_16/enyquist-X399-DESIGNARE-EX.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_21_14_23_16/enyquist-X399-DESIGNARE-EX.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /home/enyquist/repos/RLNER/models/logs/train/plugins/profile/2022_11_21_14_23_16/enyquist-X399-DESIGNARE-EX.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 9s 721ms/step - loss: 51.4722 - viterbi_accuracy: 0.8337 - val_loss: 139.4307 - val_viterbi_accuracy: 0.4410\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 44.1450 - viterbi_accuracy: 0.8214 - val_loss: 139.0988 - val_viterbi_accuracy: 0.4372\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 39.8945 - viterbi_accuracy: 0.8245 - val_loss: 139.2709 - val_viterbi_accuracy: 0.4358\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 37.4086 - viterbi_accuracy: 0.8230 - val_loss: 138.9496 - val_viterbi_accuracy: 0.4281\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 33.6558 - viterbi_accuracy: 0.8315 - val_loss: 138.5025 - val_viterbi_accuracy: 0.4398\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 31.1179 - viterbi_accuracy: 0.8315 - val_loss: 138.0072 - val_viterbi_accuracy: 0.4496\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 28.1891 - viterbi_accuracy: 0.8394 - val_loss: 136.7365 - val_viterbi_accuracy: 0.4760\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 26.2809 - viterbi_accuracy: 0.8509 - val_loss: 135.8834 - val_viterbi_accuracy: 0.4876\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 24.5305 - viterbi_accuracy: 0.8635 - val_loss: 135.6703 - val_viterbi_accuracy: 0.4945\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 21.8444 - viterbi_accuracy: 0.8786 - val_loss: 135.2014 - val_viterbi_accuracy: 0.5039\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 20.7387 - viterbi_accuracy: 0.8842 - val_loss: 134.3007 - val_viterbi_accuracy: 0.5276\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 19.0672 - viterbi_accuracy: 0.8932 - val_loss: 133.8659 - val_viterbi_accuracy: 0.5286\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 17.4794 - viterbi_accuracy: 0.9013 - val_loss: 133.0759 - val_viterbi_accuracy: 0.5429\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 16.2296 - viterbi_accuracy: 0.9077 - val_loss: 132.5357 - val_viterbi_accuracy: 0.5568\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 15.2844 - viterbi_accuracy: 0.9140 - val_loss: 132.3782 - val_viterbi_accuracy: 0.5705\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 14.2376 - viterbi_accuracy: 0.9202 - val_loss: 131.8741 - val_viterbi_accuracy: 0.5676\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 13.1803 - viterbi_accuracy: 0.9259 - val_loss: 131.1548 - val_viterbi_accuracy: 0.5797\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 12.2142 - viterbi_accuracy: 0.9298 - val_loss: 131.1299 - val_viterbi_accuracy: 0.5747\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 11.8624 - viterbi_accuracy: 0.9300 - val_loss: 130.9505 - val_viterbi_accuracy: 0.5818\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 11.4565 - viterbi_accuracy: 0.9344 - val_loss: 130.4274 - val_viterbi_accuracy: 0.5811\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 10.4004 - viterbi_accuracy: 0.9389 - val_loss: 130.5769 - val_viterbi_accuracy: 0.5781\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 9.7483 - viterbi_accuracy: 0.9426 - val_loss: 130.2230 - val_viterbi_accuracy: 0.5927\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 9.2587 - viterbi_accuracy: 0.9454 - val_loss: 129.4061 - val_viterbi_accuracy: 0.5983\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 8.6193 - viterbi_accuracy: 0.9485 - val_loss: 129.8282 - val_viterbi_accuracy: 0.5883\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 7.8704 - viterbi_accuracy: 0.9540 - val_loss: 129.4210 - val_viterbi_accuracy: 0.5941\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 7.7507 - viterbi_accuracy: 0.9550 - val_loss: 129.1028 - val_viterbi_accuracy: 0.5896\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 7.4595 - viterbi_accuracy: 0.9558 - val_loss: 128.6782 - val_viterbi_accuracy: 0.6035\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 6.9179 - viterbi_accuracy: 0.9593 - val_loss: 128.4400 - val_viterbi_accuracy: 0.6153\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 6.4446 - viterbi_accuracy: 0.9623 - val_loss: 127.9892 - val_viterbi_accuracy: 0.6163\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 6.1186 - viterbi_accuracy: 0.9643 - val_loss: 128.7280 - val_viterbi_accuracy: 0.6050\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 5.6736 - viterbi_accuracy: 0.9669 - val_loss: 127.4478 - val_viterbi_accuracy: 0.6170\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 5.6207 - viterbi_accuracy: 0.9677 - val_loss: 127.6834 - val_viterbi_accuracy: 0.6232\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 5.1538 - viterbi_accuracy: 0.9707 - val_loss: 127.6548 - val_viterbi_accuracy: 0.6017\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 5.1918 - viterbi_accuracy: 0.9698 - val_loss: 127.8541 - val_viterbi_accuracy: 0.6102\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 4.7020 - viterbi_accuracy: 0.9733 - val_loss: 127.3637 - val_viterbi_accuracy: 0.6123\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 4.4043 - viterbi_accuracy: 0.9770 - val_loss: 127.2589 - val_viterbi_accuracy: 0.6214\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 4.2061 - viterbi_accuracy: 0.9762 - val_loss: 126.5075 - val_viterbi_accuracy: 0.6435\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 3.9034 - viterbi_accuracy: 0.9798 - val_loss: 127.1736 - val_viterbi_accuracy: 0.6068\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 3.7631 - viterbi_accuracy: 0.9803 - val_loss: 126.9519 - val_viterbi_accuracy: 0.6092\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 3.5938 - viterbi_accuracy: 0.9809 - val_loss: 126.4910 - val_viterbi_accuracy: 0.6284\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 3.4965 - viterbi_accuracy: 0.9806 - val_loss: 126.9647 - val_viterbi_accuracy: 0.6126\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 3.4054 - viterbi_accuracy: 0.9827 - val_loss: 126.2718 - val_viterbi_accuracy: 0.6307\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 3.1570 - viterbi_accuracy: 0.9839 - val_loss: 126.7055 - val_viterbi_accuracy: 0.6188\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 3.1775 - viterbi_accuracy: 0.9834 - val_loss: 126.0482 - val_viterbi_accuracy: 0.6163\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 2.8701 - viterbi_accuracy: 0.9853 - val_loss: 126.1733 - val_viterbi_accuracy: 0.6287\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 2.7515 - viterbi_accuracy: 0.9850 - val_loss: 125.7491 - val_viterbi_accuracy: 0.6344\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 2.7463 - viterbi_accuracy: 0.9854 - val_loss: 125.6249 - val_viterbi_accuracy: 0.6346\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 2.6307 - viterbi_accuracy: 0.9865 - val_loss: 125.7786 - val_viterbi_accuracy: 0.6352\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 2.4737 - viterbi_accuracy: 0.9883 - val_loss: 126.3708 - val_viterbi_accuracy: 0.6240\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 2.2994 - viterbi_accuracy: 0.9888 - val_loss: 125.9531 - val_viterbi_accuracy: 0.6250\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 2.1623 - viterbi_accuracy: 0.9905 - val_loss: 126.3117 - val_viterbi_accuracy: 0.6096\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 2.2519 - viterbi_accuracy: 0.9891 - val_loss: 125.4143 - val_viterbi_accuracy: 0.6380\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 2.1215 - viterbi_accuracy: 0.9903 - val_loss: 125.9401 - val_viterbi_accuracy: 0.6245\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 2.1260 - viterbi_accuracy: 0.9899 - val_loss: 125.4921 - val_viterbi_accuracy: 0.6299\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 2.2517 - viterbi_accuracy: 0.9881 - val_loss: 124.9197 - val_viterbi_accuracy: 0.6481\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 2.2335 - viterbi_accuracy: 0.9885 - val_loss: 125.4885 - val_viterbi_accuracy: 0.6226\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, \n",
    "    histogram_freq=1,\n",
    "    profile_batch=\"1,20\"\n",
    ")\n",
    "\n",
    "\n",
    "history = model1.fit(\n",
    "    train_ds,\n",
    "    epochs=100, \n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[callback, tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline Bi-LSTM CRF model has compiled, trained, and tested on the Re3d dataset successfully! Achieving ~99.00% Accuracy on the test set, which is pretty good, as only ~68% of the tags are \"O\" tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 19ms/step - loss: 125.7402 - viterbi_accuracy: 0.6221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[125.740234375, 0.6221145391464233]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_model` creates two models, one which is trainable and one which is used for prediction. This model outputs:\n",
    "* predictions\n",
    "* LSTM hidden state forward pass\n",
    "* LSTM cell state forward pass\n",
    "* LSTM hidden state backward pass\n",
    "* LSTM cell state backward pass\n",
    "* Embeddings\n",
    "\n",
    "This is leveraged in construction of the REINFORCE states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model2.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.37701362, -0.06361421,  0.13121796, ...,  0.7053516 ,\n",
       "         0.81849736,  0.3800589 ],\n",
       "       [-0.49132574, -0.10563394,  0.28375712, ...,  0.06301506,\n",
       "         0.6918716 ,  0.69020206],\n",
       "       [-0.8381783 , -0.30090937,  0.3310538 , ...,  0.9143059 ,\n",
       "         0.773429  ,  0.20847169],\n",
       "       ...,\n",
       "       [-0.9551602 , -0.397706  ,  0.87192845, ...,  0.28784758,\n",
       "         0.21293767,  0.15012676],\n",
       "       [-0.9551803 , -0.3977052 ,  0.871945  , ...,  0.15740854,\n",
       "         0.1107231 ,  0.07684665],\n",
       "       [-0.95519596, -0.3977045 ,  0.871959  , ...,  0.06573694,\n",
       "         0.0415291 ,  0.02455554]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The LSTM hidden state forward pass of the first test sequence\n",
    "preds[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model2.predict(tf.convert_to_tensor(X[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 200)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3033, 1946, 2120, 2021,  571, 3006, 4284, 3935,  542, 3006,    8,\n",
       "        844, 2021, 2674, 3006, 2021,  350, 3587, 2313,  185, 3457, 3791,\n",
       "       2021, 3878, 3006, 4065, 2709, 1635,  930,  921, 1069, 1025, 2149,\n",
       "       4135, 2111,   24, 2944,  604,  522, 4011, 2021, 1825, 4141, 2634,\n",
       "       1316, 1316, 1316, 1316, 1316, 1316], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = {idx: word for word, idx in words2index.items()}\n",
    "index2tag = {idx: tag for tag, idx in tags2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: This \tTag: B-Temporal\n",
      "Word: week \tTag: I-Temporal\n",
      "Word: sees \tTag: O\n",
      "Word: the \tTag: O\n",
      "Word: start \tTag: O\n",
      "Word: of \tTag: O\n",
      "Word: a \tTag: O\n",
      "Word: second \tTag: O\n",
      "Word: round \tTag: O\n",
      "Word: of \tTag: O\n",
      "Word: talks \tTag: O\n",
      "Word: in \tTag: O\n",
      "Word: the \tTag: O\n",
      "Word: framework \tTag: O\n",
      "Word: of \tTag: O\n",
      "Word: the \tTag: O\n",
      "Word: European \tTag: B-Organisation\n",
      "Word: Union \tTag: I-Organisation\n",
      "Word: 's \tTag: O\n",
      "Word: Regional \tTag: O\n",
      "Word: Initiative \tTag: O\n",
      "Word: on \tTag: O\n",
      "Word: the \tTag: O\n",
      "Word: future \tTag: O\n",
      "Word: of \tTag: O\n",
      "Word: Syria \tTag: B-Location\n",
      "Word: , \tTag: O\n",
      "Word: High \tTag: B-Person\n",
      "Word: Representative \tTag: I-Person\n",
      "Word: Federica \tTag: I-Person\n",
      "Word: Mogherini \tTag: I-Person\n",
      "Word: â€™s \tTag: I-Person\n",
      "Word: initiative \tTag: O\n",
      "Word: to \tTag: O\n",
      "Word: identify \tTag: O\n",
      "Word: post \tTag: O\n",
      "Word: - \tTag: O\n",
      "Word: conflict \tTag: O\n",
      "Word: arrangements \tTag: O\n",
      "Word: for \tTag: O\n",
      "Word: the \tTag: B-Location\n",
      "Word: country \tTag: I-Location\n",
      "Word: . \tTag: O\n",
      "Word: \n",
      " \tTag: O\n",
      "Word: PADword \tTag: O\n",
      "Word: PADword \tTag: O\n",
      "Word: PADword \tTag: O\n",
      "Word: PADword \tTag: O\n",
      "Word: PADword \tTag: O\n",
      "Word: PADword \tTag: O\n"
     ]
    }
   ],
   "source": [
    "for pred, word_idx in zip(pred[0][0], X[0]):\n",
    "    word = index2word[word_idx]\n",
    "    tag_idx = np.argmax(pred)\n",
    "    tag = index2tag[tag_idx]\n",
    "    print(f\"Word: {word} \\tTag: {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'PRON', 'B-Temporal'),\n",
       " ('week', 'NOUN', 'I-Temporal'),\n",
       " ('sees', 'VERB', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('start', 'VERB', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('a', 'PRON', 'O'),\n",
       " ('second', 'ADJ', 'O'),\n",
       " ('round', 'ADJ', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('talks', 'NOUN', 'O'),\n",
       " ('in', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('framework', 'NOUN', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('European', 'ADJ', 'B-Organisation'),\n",
       " ('Union', 'NOUN', 'I-Organisation'),\n",
       " (\"'s\", 'AUX', 'O'),\n",
       " ('Regional', 'ADJ', 'O'),\n",
       " ('Initiative', 'NOUN', 'O'),\n",
       " ('on', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'O'),\n",
       " ('future', 'NOUN', 'O'),\n",
       " ('of', 'ADP', 'O'),\n",
       " ('Syria', 'PROPN', 'B-Location'),\n",
       " (',', 'PUNCT', 'O'),\n",
       " ('High', 'ADJ', 'B-Person'),\n",
       " ('Representative', 'ADJ', 'I-Person'),\n",
       " ('Federica', 'PROPN', 'I-Person'),\n",
       " ('Mogherini', 'PROPN', 'I-Person'),\n",
       " ('â€™s', 'VERB', 'I-Person'),\n",
       " ('initiative', 'NOUN', 'O'),\n",
       " ('to', 'PART', 'O'),\n",
       " ('identify', 'VERB', 'O'),\n",
       " ('post', 'ADV', 'O'),\n",
       " ('-', 'PUNCT', 'O'),\n",
       " ('conflict', 'NOUN', 'O'),\n",
       " ('arrangements', 'NOUN', 'O'),\n",
       " ('for', 'ADP', 'O'),\n",
       " ('the', 'PRON', 'B-Location'),\n",
       " ('country', 'NOUN', 'I-Location'),\n",
       " ('.', 'PUNCT', 'O'),\n",
       " ('\\n', 'SPACE', 'O')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1566ea1af4a47ca7acc671ba85a809484c1db5e7319af0d3caf0750117059574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
